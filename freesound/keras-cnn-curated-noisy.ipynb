{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split \n",
    "import librosa\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import concatenate\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_curated.csv', 'train_noisy.csv', 'sample_submission.csv', 'train_noisy', 'train_curated', 'test']\n"
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = \"input/\"\n",
    "# INPUT_FOLDER = \"../input/\"\n",
    "print(os.listdir(INPUT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CURATED_PATH = INPUT_FOLDER + \"train_curated.csv\"\n",
    "TRAIN_NOISY_PATH = INPUT_FOLDER + \"train_noisy.csv\"\n",
    "SAMPLE_SUBMISSION_PATH = INPUT_FOLDER + \"sample_submission.csv\"\n",
    "TRAIN_CURATED = INPUT_FOLDER + \"train_curated/\"\n",
    "TRAIN_NOISY = INPUT_FOLDER + \"train_noisy/\"\n",
    "TEST = INPUT_FOLDER + \"test/\"\n",
    "\n",
    "train_curated = pd.read_csv(TRAIN_CURATED_PATH)\n",
    "train_noisy = pd.read_csv(TRAIN_NOISY_PATH)\n",
    "sample = pd.read_csv(SAMPLE_SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, src_dict):\n",
    "    ar = np.zeros([len(labels), len(src_dict)])\n",
    "    for i, label in enumerate(labels):\n",
    "        label_list = label.split(',')\n",
    "        for la in label_list:\n",
    "            ar[i, src_dict[la]] = 1\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = sample.columns[1:]\n",
    "num_targets = len(target_names)\n",
    "\n",
    "src_dict = {target_names[i]:i for i in range(num_targets)}\n",
    "src_dict_inv = {i:target_names[i] for i in range(num_targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq = 128\n",
    "len_div = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(num_freq,len_div,1), name='input')\n",
    "\n",
    "dense_list = []\n",
    "\n",
    "## Block 1\n",
    "conv1 = Conv2D(4, (19, 19),activation='relu',padding='same',name='conv1')(inputs)\n",
    "pool1 = MaxPooling2D((19, 19),strides=(1, 1),padding='same',name='pool1')(conv1)\n",
    "norm1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1')(pool1)\n",
    "drop1 = Dropout(rate=0.05)(norm1)\n",
    "\n",
    "conv1_1 = Conv2D(4, (11, 11),activation='relu',padding='same',name='conv1_1')(drop1)\n",
    "pool1_1 = MaxPooling2D((5, 5),strides=(5, 5),padding='same',name='pool1_1')(conv1_1)\n",
    "norm1_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm1_1')(pool1_1)\n",
    "drop1_1 = Dropout(rate=0.05)(norm1_1)\n",
    "\n",
    "flatten1 = Flatten(name='flatten1')(drop1)\n",
    "dense1 = Dense(16, name='dense1')(flatten1)\n",
    "act1 = Activation('relu',name='act1')(dense1)\n",
    "dense_list.append(act1)\n",
    "\n",
    "## Block 2\n",
    "conv2 = Conv2D(4, (13, 13),activation='relu',padding='same',name='conv2')(inputs)\n",
    "pool2 = MaxPooling2D((13, 13), strides=(1, 1), padding='same',name='pool2')(conv2)\n",
    "norm2 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2')(pool2)\n",
    "drop2 = Dropout(rate=0.05)(norm2)\n",
    "\n",
    "conv2_1 = Conv2D(4, (7, 7),activation='relu',padding='same',name='conv2_1')(drop2)\n",
    "pool2_1 = MaxPooling2D((7, 7), strides=(5, 5), padding='same',name='pool2_1')(conv2_1)\n",
    "norm2_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,name='norm2_1')(pool2_1)\n",
    "drop2_1 = Dropout(rate=0.05)(norm2_1)\n",
    "\n",
    "flatten2 = Flatten(name='flatten2')(drop2_1)\n",
    "dense2 = Dense(16, name='dense2')(flatten2)\n",
    "act2 = Activation('relu',name='act2')(dense2)\n",
    "dense_list.append(act2)\n",
    "\n",
    "## Block 3\n",
    "conv3 = Conv2D(8, (11, 11), activation='relu',padding='same',name='conv3')(inputs)\n",
    "pool3 = MaxPooling2D((11, 11), strides=(2, 2), padding='same',name='pool3')(conv3)\n",
    "norm3 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3')(pool3)\n",
    "drop3 = Dropout(rate=0.05)(norm3)\n",
    "\n",
    "conv3_1 = Conv2D(8, (5, 5), activation='relu',padding='same',name='conv3_1')(drop3)\n",
    "pool3_1 = MaxPooling2D((5, 5), strides=(2, 2), padding='same',name='pool3_1')(conv3_1)\n",
    "norm3_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm3_1')(pool3_1)\n",
    "drop3_1 = Dropout(rate=0.05)(norm3_1)\n",
    "\n",
    "flatten3 = Flatten(name='flatten3')(drop3_1)\n",
    "dense3 = Dense(16, name='dense3')(flatten3)\n",
    "act3 = Activation('relu',name='act3')(dense3)\n",
    "dense_list.append(act3)\n",
    "\n",
    "## Block 4\n",
    "conv4 = Conv2D(8, (9, 9),activation='relu',padding='same',name='conv4')(inputs)\n",
    "pool4 = MaxPooling2D((9, 9), strides=(2, 2), padding='same',name='pool4')(conv4)\n",
    "norm4 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4')(pool4)\n",
    "drop4 = Dropout(rate=0.05)(norm4)\n",
    "\n",
    "conv4_1 = Conv2D(8, (3, 3),activation='relu',padding='same',name='conv4_1')(drop4)\n",
    "pool4_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='same',name='pool4_1')(conv4_1)\n",
    "norm4_1 = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001,name='norm4_1')(pool4_1)\n",
    "drop4_1 = Dropout(rate=0.05)(norm4_1)\n",
    "\n",
    "flatten4 = Flatten(name='flatten4')(drop4_1)\n",
    "dense4 = Dense(16, name='dense4')(flatten4)\n",
    "act4 = Activation('relu',name='act4')(dense4)\n",
    "dense_list.append(act4)\n",
    "\n",
    "concat = concatenate(dense_list, name='concat', axis=1)\n",
    "\n",
    "dense2 = Dense(80, name='dense_all')(concat)\n",
    "pred = Activation('softmax',name='pred')(dense2)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "           rotation_range=0,\n",
    "           width_shift_range=16,\n",
    "           height_shift_range=0,\n",
    "           shear_range=0,\n",
    "           zoom_range=0,\n",
    "           horizontal_flip=False,\n",
    "           vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = train_curated['fname'].values\n",
    "# y_proc_tmp = one_hot(train_curated['labels'], src_dict)\n",
    "\n",
    "# X_proc_ = np.zeros([1, num_freq, len_div])\n",
    "# y_proc_ = np.zeros([1,80])\n",
    "# for i, file in enumerate(file_name):\n",
    "#     wavfile = TRAIN_CURATED + file\n",
    "#     y_proc, sr = librosa.load(wavfile)\n",
    "#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "#     log_S = librosa.power_to_db(S, ref=np.max)\n",
    "#     X_proc = (log_S + 80) / 40 - 1\n",
    "\n",
    "#     num_div = X_proc.shape[1] // len_div\n",
    "#     num_pad = len_div - X_proc.shape[1] % len_div\n",
    "#     redidual_amp = np.zeros([num_freq, num_pad])\n",
    "#     dum = np.hstack([X_proc, redidual_amp])\n",
    "#     X_proc_ = np.vstack([X_proc_, np.array(np.split(dum, num_div+1,1))])\n",
    "#     for _ in range(num_div+1):\n",
    "#         y_proc_ = np.vstack([y_proc_, y_proc_tmp[i+div*k]])\n",
    "\n",
    "# X_train = X_proc_[1:]\n",
    "# y_train = y_proc_[1:]\n",
    "# X_train = X_train.reshape([-1, num_freq, len_div, 1])\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_arr.pickle', 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "    y_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "294/293 [==============================] - 114s 389ms/step - loss: 6.3323 - acc: 0.0451\n",
      "Epoch 2/10\n",
      "294/293 [==============================] - 111s 378ms/step - loss: 5.1486 - acc: 0.0892\n",
      "Epoch 3/10\n",
      "294/293 [==============================] - 111s 379ms/step - loss: 4.5027 - acc: 0.1244\n",
      "Epoch 4/10\n",
      "294/293 [==============================] - 112s 381ms/step - loss: 4.2593 - acc: 0.1481\n",
      "Epoch 5/10\n",
      "294/293 [==============================] - 112s 382ms/step - loss: 3.9094 - acc: 0.1819\n",
      "Epoch 6/10\n",
      "294/293 [==============================] - 112s 381ms/step - loss: 3.7550 - acc: 0.1935\n",
      "Epoch 7/10\n",
      "294/293 [==============================] - 112s 380ms/step - loss: 3.5741 - acc: 0.2263\n",
      "Epoch 8/10\n",
      "294/293 [==============================] - 112s 381ms/step - loss: 3.4044 - acc: 0.2536\n",
      "Epoch 9/10\n",
      "294/293 [==============================] - 111s 378ms/step - loss: 3.2498 - acc: 0.2807\n",
      "Epoch 10/10\n",
      "294/293 [==============================] - 110s 376ms/step - loss: 3.1492 - acc: 0.2981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7176e805f8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen.fit(X_train)\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/45 [==============================] - 19s 407ms/step - loss: 3.3391 - acc: 0.3351\n",
      "Epoch 2/10\n",
      "12/45 [======>.......................] - ETA: 12s - loss: 3.2306 - acc: 0.3151"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-af117a057dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model1.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n\u001b[0;32m----> 4\u001b[0;31m                     steps_per_epoch=len(X_train) / 32, epochs=10)\n\u001b[0m",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = model\n",
    "datagen.fit(X_train)\n",
    "model1.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 393ms/step - loss: 5.3930 - acc: 0.0557\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 4.6812 - acc: 0.0773\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 4.4690 - acc: 0.1046\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 398ms/step - loss: 4.8179 - acc: 0.0920\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 4.5058 - acc: 0.1103\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 4.2733 - acc: 0.1381\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 4.7279 - acc: 0.1033\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 4.4133 - acc: 0.1250\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 381ms/step - loss: 4.1513 - acc: 0.1501\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 4.7435 - acc: 0.0858\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 17s 372ms/step - loss: 4.4159 - acc: 0.1114\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 17s 372ms/step - loss: 4.2166 - acc: 0.1364\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 397ms/step - loss: 4.6733 - acc: 0.1165\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 4.3527 - acc: 0.1395\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 4.1824 - acc: 0.1771\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 394ms/step - loss: 4.5469 - acc: 0.1181\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 4.2334 - acc: 0.1407\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 3.9978 - acc: 0.1709\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 4.4517 - acc: 0.1266\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 4.1974 - acc: 0.1563\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 3.9590 - acc: 0.1845\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 382ms/step - loss: 4.5232 - acc: 0.1370\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 4.2735 - acc: 0.1696\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 4.0395 - acc: 0.1985\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.0791 - acc: 0.1347\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8102 - acc: 0.1783\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6262 - acc: 0.2057\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.4594 - acc: 0.1247\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 4.0787 - acc: 0.1673\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8628 - acc: 0.1885\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 399ms/step - loss: 4.3654 - acc: 0.1406\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 380ms/step - loss: 3.9755 - acc: 0.1915\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7690 - acc: 0.2277\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 394ms/step - loss: 4.3428 - acc: 0.1502\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.9829 - acc: 0.1978\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8403 - acc: 0.2178\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 394ms/step - loss: 4.1620 - acc: 0.1420\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.8176 - acc: 0.1861\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6562 - acc: 0.1999\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 4.2667 - acc: 0.1569\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.8682 - acc: 0.2228\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.6891 - acc: 0.2283\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 401ms/step - loss: 4.3264 - acc: 0.1585\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9665 - acc: 0.2034\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7893 - acc: 0.2265\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 4.3690 - acc: 0.1690\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.9539 - acc: 0.2095\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.7972 - acc: 0.2291\n",
      "Epoch 1/3\n",
      "29/28 [==============================] - 12s 406ms/step - loss: 4.1997 - acc: 0.1364\n",
      "Epoch 2/3\n",
      "29/28 [==============================] - 11s 379ms/step - loss: 3.7458 - acc: 0.2090\n",
      "Epoch 3/3\n",
      "29/28 [==============================] - 11s 379ms/step - loss: 3.5327 - acc: 0.2486\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 393ms/step - loss: 4.2679 - acc: 0.1529\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 376ms/step - loss: 3.9133 - acc: 0.2165\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 377ms/step - loss: 3.7564 - acc: 0.2425\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 4.3255 - acc: 0.1407\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.9573 - acc: 0.1920\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.7663 - acc: 0.2056\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 4.2742 - acc: 0.1384\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.9336 - acc: 0.1916\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.7694 - acc: 0.2162\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 400ms/step - loss: 3.9410 - acc: 0.1761\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6648 - acc: 0.2101\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5250 - acc: 0.2256\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.3391 - acc: 0.1475\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9931 - acc: 0.1700\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7896 - acc: 0.2082\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.1273 - acc: 0.1777\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7948 - acc: 0.2116\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 380ms/step - loss: 3.6321 - acc: 0.2324\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.3007 - acc: 0.1907\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.9529 - acc: 0.2327\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.7867 - acc: 0.2467\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 4.2047 - acc: 0.1696\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.8638 - acc: 0.2102\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.7057 - acc: 0.2242\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.2874 - acc: 0.1802\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9451 - acc: 0.2184\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7552 - acc: 0.2446\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 397ms/step - loss: 4.0637 - acc: 0.1720\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7698 - acc: 0.2053\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6161 - acc: 0.2307\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9922 - acc: 0.1974\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7047 - acc: 0.2199\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.5584 - acc: 0.2559\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.9309 - acc: 0.1774\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6351 - acc: 0.2209\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/45 [==============================] - 18s 382ms/step - loss: 3.4849 - acc: 0.2489\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.0970 - acc: 0.1819\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8070 - acc: 0.2089\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6417 - acc: 0.2325\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.0251 - acc: 0.1872\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7012 - acc: 0.2336\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5143 - acc: 0.2612\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.0962 - acc: 0.1826\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.7448 - acc: 0.2258\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5721 - acc: 0.2527\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.1694 - acc: 0.1810\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 380ms/step - loss: 3.8375 - acc: 0.2452\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6537 - acc: 0.2613\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.9644 - acc: 0.1791\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6507 - acc: 0.2086\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5027 - acc: 0.2405\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.7473 - acc: 0.2000\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.4300 - acc: 0.2625\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.2632 - acc: 0.2826\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 385ms/step - loss: 4.2491 - acc: 0.1776\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 3.9113 - acc: 0.2278\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 3.7395 - acc: 0.2471\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 394ms/step - loss: 4.0642 - acc: 0.1787\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8088 - acc: 0.1952\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5868 - acc: 0.2399\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8869 - acc: 0.2006\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5944 - acc: 0.2306\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.3733 - acc: 0.2515\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.9857 - acc: 0.1936\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.5744 - acc: 0.2448\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.4177 - acc: 0.2647\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.3119 - acc: 0.1504\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9183 - acc: 0.2061\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7862 - acc: 0.2303\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.7841 - acc: 0.2045\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.4965 - acc: 0.2484\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.3542 - acc: 0.2549\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8190 - acc: 0.2013\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5132 - acc: 0.2421\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.3354 - acc: 0.2696\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9042 - acc: 0.2049\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5650 - acc: 0.2349\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4072 - acc: 0.2586\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9998 - acc: 0.1837\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6686 - acc: 0.2400\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5133 - acc: 0.2463\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 4.1564 - acc: 0.1802\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8028 - acc: 0.2293\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6729 - acc: 0.2448\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9444 - acc: 0.2038\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.6727 - acc: 0.2448\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5025 - acc: 0.2679\n",
      "Epoch 1/3\n",
      "29/28 [==============================] - 11s 381ms/step - loss: 3.9757 - acc: 0.1767\n",
      "Epoch 2/3\n",
      "29/28 [==============================] - 11s 381ms/step - loss: 3.5599 - acc: 0.2434\n",
      "Epoch 3/3\n",
      "29/28 [==============================] - 11s 380ms/step - loss: 3.3550 - acc: 0.2620\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.8524 - acc: 0.1952\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5386 - acc: 0.2325\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.3487 - acc: 0.2522\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.7157 - acc: 0.2577\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.4930 - acc: 0.2627\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.3156 - acc: 0.3142\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.6289 - acc: 0.2245\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.3196 - acc: 0.2614\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.1650 - acc: 0.2906\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.9250 - acc: 0.2063\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5935 - acc: 0.2582\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.4722 - acc: 0.2685\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.9443 - acc: 0.1997\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 383ms/step - loss: 3.6579 - acc: 0.2351\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 383ms/step - loss: 3.5125 - acc: 0.2779\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.0060 - acc: 0.1845\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6951 - acc: 0.2304\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5584 - acc: 0.2423\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.0678 - acc: 0.2038\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.7047 - acc: 0.2520\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5599 - acc: 0.2763\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9294 - acc: 0.1905\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6181 - acc: 0.2247\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4955 - acc: 0.2453\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.9244 - acc: 0.1919\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6391 - acc: 0.2212\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4853 - acc: 0.2492\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 4.3148 - acc: 0.1896\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.9420 - acc: 0.2275\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.7676 - acc: 0.2335\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 4.1520 - acc: 0.1763\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/46 [==============================] - 18s 375ms/step - loss: 3.8859 - acc: 0.2155\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.6938 - acc: 0.2567\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.0153 - acc: 0.2017\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7050 - acc: 0.2493\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5605 - acc: 0.2721\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9814 - acc: 0.2171\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6819 - acc: 0.2368\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5078 - acc: 0.2679\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8821 - acc: 0.2146\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6077 - acc: 0.2614\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4281 - acc: 0.2751\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.1148 - acc: 0.2251\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.7955 - acc: 0.2563\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6161 - acc: 0.2836\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 4.0258 - acc: 0.1916\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.6493 - acc: 0.2308\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.5382 - acc: 0.2481\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.9524 - acc: 0.2031\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6366 - acc: 0.2492\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4900 - acc: 0.2805\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 4.0283 - acc: 0.1823\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.6841 - acc: 0.2178\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.5911 - acc: 0.2378\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7993 - acc: 0.2134\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.4985 - acc: 0.2543\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.3754 - acc: 0.2754\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8870 - acc: 0.1980\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6164 - acc: 0.2397\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4785 - acc: 0.2436\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.0122 - acc: 0.2164\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7588 - acc: 0.2353\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5932 - acc: 0.2519\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 4.0963 - acc: 0.2085\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.8285 - acc: 0.2368\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.6618 - acc: 0.2461\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.9859 - acc: 0.1999\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.7042 - acc: 0.2364\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.5315 - acc: 0.2657\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.9958 - acc: 0.1897\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7540 - acc: 0.2124\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5922 - acc: 0.2377\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 383ms/step - loss: 3.8194 - acc: 0.1990\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.5367 - acc: 0.2330\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.3754 - acc: 0.2554\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8862 - acc: 0.2209\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6199 - acc: 0.2640\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4819 - acc: 0.2749\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9928 - acc: 0.1974\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6782 - acc: 0.2457\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5458 - acc: 0.2674\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 4.0314 - acc: 0.2056\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7156 - acc: 0.2399\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5712 - acc: 0.2599\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.0365 - acc: 0.1986\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7550 - acc: 0.2461\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6096 - acc: 0.2701\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7709 - acc: 0.2246\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4589 - acc: 0.2679\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.2941 - acc: 0.2904\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.1739 - acc: 0.1728\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8368 - acc: 0.2230\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6482 - acc: 0.2430\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.9830 - acc: 0.2074\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.7482 - acc: 0.2339\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5819 - acc: 0.2565\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9257 - acc: 0.2062\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6716 - acc: 0.2465\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5161 - acc: 0.2668\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.8399 - acc: 0.2252\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5206 - acc: 0.2690\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.3524 - acc: 0.2943\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6912 - acc: 0.2223\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4439 - acc: 0.2653\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.3257 - acc: 0.2926\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7905 - acc: 0.2282\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4932 - acc: 0.2477\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.3516 - acc: 0.2758\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8892 - acc: 0.1947\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6210 - acc: 0.2413\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.4414 - acc: 0.2632\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8475 - acc: 0.2058\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5731 - acc: 0.2533\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4147 - acc: 0.2685\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.9489 - acc: 0.2217\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6550 - acc: 0.2633\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.5249 - acc: 0.2816\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8574 - acc: 0.2011\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5716 - acc: 0.2516\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4119 - acc: 0.2665\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 4.1224 - acc: 0.1906\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 3.8187 - acc: 0.2268\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.6999 - acc: 0.2388\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6711 - acc: 0.2259\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.4050 - acc: 0.2635\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.2645 - acc: 0.2785\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 4.0315 - acc: 0.1868\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7432 - acc: 0.2471\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5549 - acc: 0.2735\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.9504 - acc: 0.1906\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6686 - acc: 0.2158\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4923 - acc: 0.2613\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.7680 - acc: 0.2101\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4638 - acc: 0.2658\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.2888 - acc: 0.2924\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9656 - acc: 0.2185\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6494 - acc: 0.2531\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5132 - acc: 0.2726\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 4.0120 - acc: 0.2301\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.7104 - acc: 0.2488\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.6063 - acc: 0.2784\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.0254 - acc: 0.1952\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7553 - acc: 0.2293\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6401 - acc: 0.2430\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9100 - acc: 0.2054\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6274 - acc: 0.2352\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4700 - acc: 0.2630\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8947 - acc: 0.2011\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.6110 - acc: 0.2206\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4560 - acc: 0.2444\n",
      "Epoch 1/3\n",
      "29/28 [==============================] - 11s 382ms/step - loss: 3.8634 - acc: 0.1822\n",
      "Epoch 2/3\n",
      "29/28 [==============================] - 11s 380ms/step - loss: 3.4963 - acc: 0.2597\n",
      "Epoch 3/3\n",
      "29/28 [==============================] - 11s 380ms/step - loss: 3.2907 - acc: 0.2744\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7847 - acc: 0.2149\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.5032 - acc: 0.2545\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.3635 - acc: 0.2742\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.6341 - acc: 0.2642\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.3601 - acc: 0.2889\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 380ms/step - loss: 3.2488 - acc: 0.3030\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.9158 - acc: 0.2147\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 381ms/step - loss: 3.6095 - acc: 0.2412\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 381ms/step - loss: 3.4682 - acc: 0.2670\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.8406 - acc: 0.2218\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.5419 - acc: 0.2521\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.4453 - acc: 0.2681\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.7968 - acc: 0.2281\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5587 - acc: 0.2593\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.4228 - acc: 0.2813\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.7973 - acc: 0.2112\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5676 - acc: 0.2634\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.3947 - acc: 0.2851\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.7436 - acc: 0.2066\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.4429 - acc: 0.2509\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.3065 - acc: 0.2781\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.8173 - acc: 0.2235\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.4431 - acc: 0.2783\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 373ms/step - loss: 3.5035 - acc: 0.2909\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.8872 - acc: 0.1766\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.5820 - acc: 0.2317\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 382ms/step - loss: 3.3798 - acc: 0.2629\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 4.1258 - acc: 0.2245\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.8134 - acc: 0.2494\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.6313 - acc: 0.2747\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5919 - acc: 0.2246\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.3092 - acc: 0.2654\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.1360 - acc: 0.2959\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 4.0391 - acc: 0.2409\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.7593 - acc: 0.2645\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5876 - acc: 0.2934\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 380ms/step - loss: 3.8516 - acc: 0.2219\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5976 - acc: 0.2535\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4481 - acc: 0.2810\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8605 - acc: 0.2346\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5587 - acc: 0.2833\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4234 - acc: 0.2919\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8446 - acc: 0.2107\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6281 - acc: 0.2574\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4291 - acc: 0.2731\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.9039 - acc: 0.2122\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.6647 - acc: 0.2564\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.5534 - acc: 0.2497\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9450 - acc: 0.2047\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6956 - acc: 0.2456\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5247 - acc: 0.2746\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8347 - acc: 0.2300\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5677 - acc: 0.2540\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4575 - acc: 0.2771\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.9598 - acc: 0.2131\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6555 - acc: 0.2683\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5133 - acc: 0.2953\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.8404 - acc: 0.2002\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.7134 - acc: 0.2282\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.4877 - acc: 0.2581\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9216 - acc: 0.2089\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6495 - acc: 0.2491\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.4805 - acc: 0.2901\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.9612 - acc: 0.2136\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6636 - acc: 0.2533\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5433 - acc: 0.2633\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5709 - acc: 0.2193\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.3433 - acc: 0.2600\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.2202 - acc: 0.2754\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.9036 - acc: 0.2602\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6361 - acc: 0.2869\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4742 - acc: 0.3081\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.7968 - acc: 0.2188\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4754 - acc: 0.2729\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.3358 - acc: 0.2898\n",
      "Epoch 1/3\n",
      "29/28 [==============================] - 11s 381ms/step - loss: 3.7886 - acc: 0.2184\n",
      "Epoch 2/3\n",
      "29/28 [==============================] - 11s 379ms/step - loss: 3.4525 - acc: 0.2638\n",
      "Epoch 3/3\n",
      "29/28 [==============================] - 11s 379ms/step - loss: 3.2830 - acc: 0.2796\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8121 - acc: 0.2485\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5294 - acc: 0.2826\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.3586 - acc: 0.3001\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.6865 - acc: 0.2435\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.4665 - acc: 0.2800\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.2708 - acc: 0.2940\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8865 - acc: 0.2361\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6291 - acc: 0.2618\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.4718 - acc: 0.2858\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.7845 - acc: 0.2361\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.4858 - acc: 0.2508\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.4015 - acc: 0.2800\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.7993 - acc: 0.2223\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5501 - acc: 0.2686\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.3905 - acc: 0.3039\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 376ms/step - loss: 3.8936 - acc: 0.1956\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.5970 - acc: 0.2282\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 374ms/step - loss: 3.4984 - acc: 0.2670\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.8043 - acc: 0.2232\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.5187 - acc: 0.2554\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 378ms/step - loss: 3.3970 - acc: 0.2759\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.8686 - acc: 0.2052\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.6238 - acc: 0.2283\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4540 - acc: 0.2579\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8447 - acc: 0.2082\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5944 - acc: 0.2517\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.4361 - acc: 0.2729\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.7165 - acc: 0.2293\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.4362 - acc: 0.2542\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 379ms/step - loss: 3.2961 - acc: 0.2834\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5384 - acc: 0.2476\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.2754 - acc: 0.2885\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.1108 - acc: 0.3175\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 377ms/step - loss: 3.8533 - acc: 0.2198\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.5790 - acc: 0.2584\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 375ms/step - loss: 3.4492 - acc: 0.2634\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.8942 - acc: 0.1982\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5817 - acc: 0.2472\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.4432 - acc: 0.2607\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6276 - acc: 0.2525\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.3321 - acc: 0.3021\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.2087 - acc: 0.2922\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8590 - acc: 0.2165\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5698 - acc: 0.2527\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.4270 - acc: 0.2602\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.9307 - acc: 0.1974\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.6998 - acc: 0.2279\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.5597 - acc: 0.2389\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 381ms/step - loss: 3.8240 - acc: 0.2212\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 17s 380ms/step - loss: 3.5951 - acc: 0.2523\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 395ms/step - loss: 3.4706 - acc: 0.2751\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 19s 397ms/step - loss: 3.9300 - acc: 0.2251\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 389ms/step - loss: 3.7230 - acc: 0.2501\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 386ms/step - loss: 3.5277 - acc: 0.3026\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.8253 - acc: 0.1889\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.5955 - acc: 0.2186\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.4294 - acc: 0.2392\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 4.0438 - acc: 0.1922\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/45 [==============================] - 18s 386ms/step - loss: 3.7468 - acc: 0.2305\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.6072 - acc: 0.2502\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.9709 - acc: 0.1909\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 383ms/step - loss: 3.6674 - acc: 0.2391\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 383ms/step - loss: 3.5538 - acc: 0.2694\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.8247 - acc: 0.2187\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.5727 - acc: 0.2621\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.4082 - acc: 0.3011\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.7942 - acc: 0.2204\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.5215 - acc: 0.2696\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.3820 - acc: 0.2733\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 393ms/step - loss: 3.7804 - acc: 0.2154\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 392ms/step - loss: 3.4952 - acc: 0.2500\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 392ms/step - loss: 3.3423 - acc: 0.2765\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.8547 - acc: 0.2354\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.6018 - acc: 0.2781\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 396ms/step - loss: 3.4632 - acc: 0.2939\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.7359 - acc: 0.2248\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.4083 - acc: 0.2657\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.2599 - acc: 0.2842\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 393ms/step - loss: 3.6548 - acc: 0.2251\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.3911 - acc: 0.2604\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.2445 - acc: 0.2950\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 386ms/step - loss: 3.9972 - acc: 0.2172\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.7103 - acc: 0.2378\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 385ms/step - loss: 3.6176 - acc: 0.2561\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.7893 - acc: 0.2486\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.5050 - acc: 0.2697\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.3536 - acc: 0.2913\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.9280 - acc: 0.2326\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6456 - acc: 0.2584\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.5008 - acc: 0.2953\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.9077 - acc: 0.2153\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.6085 - acc: 0.2677\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.4607 - acc: 0.2750\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.9330 - acc: 0.2224\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6856 - acc: 0.2580\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.5290 - acc: 0.2761\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 393ms/step - loss: 3.8791 - acc: 0.2058\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 391ms/step - loss: 3.5776 - acc: 0.2500\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 389ms/step - loss: 3.4352 - acc: 0.2819\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.6466 - acc: 0.2427\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.3647 - acc: 0.2841\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.2533 - acc: 0.2978\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.7345 - acc: 0.2325\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.5034 - acc: 0.2732\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.3440 - acc: 0.3018\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.8082 - acc: 0.2131\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.5431 - acc: 0.2500\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.3893 - acc: 0.2897\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.7776 - acc: 0.2087\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.5202 - acc: 0.2409\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 392ms/step - loss: 3.3807 - acc: 0.2626\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.6610 - acc: 0.2325\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.4177 - acc: 0.2634\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.2521 - acc: 0.2868\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 393ms/step - loss: 3.5831 - acc: 0.2669\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.2922 - acc: 0.3079\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.1535 - acc: 0.3200\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 385ms/step - loss: 3.9455 - acc: 0.1969\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.6128 - acc: 0.2344\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 383ms/step - loss: 3.4887 - acc: 0.2581\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.7796 - acc: 0.2200\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.5147 - acc: 0.2518\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.3419 - acc: 0.2913\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.8050 - acc: 0.2142\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.4890 - acc: 0.2785\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.3417 - acc: 0.3121\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.9901 - acc: 0.1981\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6851 - acc: 0.2464\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.5332 - acc: 0.2792\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 392ms/step - loss: 3.7486 - acc: 0.2255\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 390ms/step - loss: 3.4656 - acc: 0.2670\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 392ms/step - loss: 3.3015 - acc: 0.2765\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.8538 - acc: 0.2285\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.5493 - acc: 0.2574\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.3593 - acc: 0.2877\n",
      "Epoch 1/3\n",
      "46/46 [==============================] - 18s 391ms/step - loss: 3.7206 - acc: 0.2249\n",
      "Epoch 2/3\n",
      "46/46 [==============================] - 18s 389ms/step - loss: 3.4715 - acc: 0.2792\n",
      "Epoch 3/3\n",
      "46/46 [==============================] - 18s 389ms/step - loss: 3.3696 - acc: 0.2921\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 395ms/step - loss: 3.5833 - acc: 0.2483\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 396ms/step - loss: 3.3047 - acc: 0.2932\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 394ms/step - loss: 3.1766 - acc: 0.3090\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.7511 - acc: 0.1984\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.5062 - acc: 0.2310\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.3549 - acc: 0.2693\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/45 [==============================] - 18s 388ms/step - loss: 3.9668 - acc: 0.1890\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.6574 - acc: 0.2531\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.5173 - acc: 0.2590\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.8348 - acc: 0.2299\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.5856 - acc: 0.2887\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.4234 - acc: 0.3068\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.7049 - acc: 0.2396\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.4506 - acc: 0.2710\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.2720 - acc: 0.3105\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 380ms/step - loss: 3.6050 - acc: 0.2441\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 3.3653 - acc: 0.2754\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 3.2376 - acc: 0.2887\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.7414 - acc: 0.2416\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.4988 - acc: 0.2697\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.3537 - acc: 0.2811\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 382ms/step - loss: 3.9378 - acc: 0.2172\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 381ms/step - loss: 3.6752 - acc: 0.2504\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 382ms/step - loss: 3.5028 - acc: 0.2710\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.7629 - acc: 0.2326\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.5341 - acc: 0.2704\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.4140 - acc: 0.2758\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.7954 - acc: 0.2334\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.5299 - acc: 0.2805\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.3866 - acc: 0.2992\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.7917 - acc: 0.2270\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.5414 - acc: 0.2688\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.4052 - acc: 0.2783\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.9632 - acc: 0.2351\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.6956 - acc: 0.2801\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.5346 - acc: 0.3014\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 381ms/step - loss: 3.9032 - acc: 0.2295\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 380ms/step - loss: 3.6463 - acc: 0.2634\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 380ms/step - loss: 3.5036 - acc: 0.2860\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 384ms/step - loss: 3.7580 - acc: 0.2210\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 382ms/step - loss: 3.5285 - acc: 0.2510\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 383ms/step - loss: 3.4050 - acc: 0.2796\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 3.8095 - acc: 0.2195\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 3.5434 - acc: 0.2481\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 378ms/step - loss: 3.4034 - acc: 0.2761\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.6266 - acc: 0.2243\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 385ms/step - loss: 3.3951 - acc: 0.2535\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.2214 - acc: 0.2876\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.8465 - acc: 0.2353\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.5669 - acc: 0.2809\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.4450 - acc: 0.2851\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.7963 - acc: 0.2081\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.5094 - acc: 0.2695\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.3793 - acc: 0.2986\n",
      "Epoch 1/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.9998 - acc: 0.2012\n",
      "Epoch 2/3\n",
      "47/46 [==============================] - 18s 384ms/step - loss: 3.7190 - acc: 0.2464\n",
      "Epoch 3/3\n",
      "47/46 [==============================] - 18s 383ms/step - loss: 3.5853 - acc: 0.2667\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6088 - acc: 0.2289\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.3648 - acc: 0.2610\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.2450 - acc: 0.2767\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.9165 - acc: 0.2144\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6233 - acc: 0.2656\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.4424 - acc: 0.2847\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.7602 - acc: 0.2355\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.4869 - acc: 0.2668\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.3229 - acc: 0.3072\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.6095 - acc: 0.2440\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.3450 - acc: 0.2821\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.2327 - acc: 0.2991\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.7428 - acc: 0.2284\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 388ms/step - loss: 3.5076 - acc: 0.2628\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.3994 - acc: 0.2776\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.5114 - acc: 0.2415\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.2119 - acc: 0.2912\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.0913 - acc: 0.3069\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.7979 - acc: 0.2170\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.5190 - acc: 0.2661\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 386ms/step - loss: 3.3605 - acc: 0.2738\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.9527 - acc: 0.2264\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.6443 - acc: 0.2762\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 390ms/step - loss: 3.4981 - acc: 0.2939\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 391ms/step - loss: 3.7320 - acc: 0.2212\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.4838 - acc: 0.2682\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.3301 - acc: 0.3010\n",
      "Epoch 1/3\n",
      "29/28 [==============================] - 11s 388ms/step - loss: 3.7332 - acc: 0.2308\n",
      "Epoch 2/3\n",
      "29/28 [==============================] - 11s 386ms/step - loss: 3.3758 - acc: 0.2735\n",
      "Epoch 3/3\n",
      "29/28 [==============================] - 11s 387ms/step - loss: 3.2208 - acc: 0.2925\n",
      "Epoch 1/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.8451 - acc: 0.2430\n",
      "Epoch 2/3\n",
      "46/45 [==============================] - 18s 387ms/step - loss: 3.5630 - acc: 0.2822\n",
      "Epoch 3/3\n",
      "46/45 [==============================] - 18s 389ms/step - loss: 3.4380 - acc: 0.3184\n",
      "noisy iter epoch No.4 is done.\n"
     ]
    }
   ],
   "source": [
    "file_name = train_noisy['fname'].values\n",
    "\n",
    "div = 500\n",
    "num_batch = len(file_name) // div\n",
    "rest = len(file_name) % div\n",
    "\n",
    "pos = [range(div*k, div*(k+1)) for k in range(num_batch)]\n",
    "pos.append(range(div*num_batch, div*num_batch+rest))\n",
    "\n",
    "y_proc_tmp = one_hot(train_noisy['labels'], src_dict)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    k_list = random.sample(range(num_batch+1), num_batch+1)\n",
    "    for k in k_list:\n",
    "    #     X_proc_ = np.zeros([1, num_freq, len_div])\n",
    "    #     y_proc_ = np.zeros([1,80])\n",
    "    #     for i, file in enumerate(file_name[pos[k]]):\n",
    "    #         wavfile = TRAIN_NOISY + file\n",
    "    #         y_proc, sr = librosa.load(wavfile)\n",
    "    #         S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "    #         log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    #         X_proc = (log_S + 80) / 40 - 1\n",
    "\n",
    "    #         num_div = X_proc.shape[1] // len_div\n",
    "    #         num_pad = len_div - X_proc.shape[1] % len_div\n",
    "    #         redidual_amp = np.zeros([num_freq, num_pad])\n",
    "    #         dum = np.hstack([X_proc, redidual_amp])\n",
    "    #         X_proc_ = np.vstack([X_proc_, np.array(np.split(dum, num_div+1,1))])\n",
    "    #         for _ in range(num_div+1):\n",
    "    #             y_proc_ = np.vstack([y_proc_, y_proc_tmp[i+div*k]])\n",
    "\n",
    "    #     X_train = X_proc_[1:]\n",
    "    #     y_train = y_proc_[1:]\n",
    "    #     X_train = X.reshape([-1, num_freq, len_div, 1])\n",
    "\n",
    "        with open('out/train_noisy_arr_{}.pickle'.format(k), 'rb') as f:\n",
    "            X_train = pickle.load(f)\n",
    "            y_train = pickle.load(f)\n",
    "\n",
    "        datagen.fit(X_train)\n",
    "        model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                            steps_per_epoch=len(X_train) / 32, epochs=3)\n",
    "print('noisy iter epoch No.{} is done.'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20190506model_curated_noisy.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20190506model_curated_noisy.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_list = []\n",
    "\n",
    "filename = glob.glob(TEST + \"*\")\n",
    "\n",
    "for file in filename:\n",
    "    wavfile = file\n",
    "    y_proc, sr = librosa.load(wavfile)\n",
    "    S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    X_proc = (log_S + 80) / 40 - 1\n",
    "    \n",
    "    num_div = X_proc.shape[1] // len_div\n",
    "    num_pad = len_div - X_proc.shape[1] % len_div\n",
    "    redidual_amp = np.zeros([num_freq, num_pad])\n",
    "    dum = np.hstack([X_proc, redidual_amp])\n",
    "    X_test_list.append(np.array(np.split(dum, num_div+1,1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/test_arr.pickle', 'wb') as f:\n",
    "    pickle.dump(X_test_list, f)\n",
    "    pickle.dump(filename, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/test_arr.pickle', 'rb') as f:\n",
    "    X_test_list = pickle.load(f)\n",
    "    filename = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_list = []\n",
    "\n",
    "# for file in filename:\n",
    "#     wavfile = file\n",
    "#     y_proc, sr = librosa.load(wavfile)\n",
    "#     S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "#     log_S = librosa.power_to_db(S, ref=np.max)\n",
    "#     X_proc = (log_S + 80) / 40 - 1\n",
    "    \n",
    "#     num_div = X_proc.shape[1] // len_div\n",
    "#     num_pad = len_div - X_proc.shape[1] % len_div\n",
    "#     redidual_amp = np.zeros([num_freq, num_pad])\n",
    "#     dum = np.hstack([X_proc, redidual_amp])\n",
    "#     X_test_list.append(np.array(np.split(dum, num_div+1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for X_test in X_test_list:\n",
    "    pred = model.predict(X_test.reshape([-1, num_freq, len_div,1])).sum(axis=0) / len(X_test)\n",
    "    pred_list.append(pred)\n",
    "y_pred = np.array(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_names = sample.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for f in filename:\n",
    "    names.append(f.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_file = pd.Series(names, name='fname')\n",
    "label = pd.DataFrame(y_pred, columns=sound_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.concat([se_file, label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
