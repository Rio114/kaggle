{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split \n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_curated.csv', 'train_noisy.csv', 'sample_submission.csv', 'train_noisy', 'train_curated', 'test']\n"
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = \"input/\"\n",
    "# INPUT_FOLDER = \"../input/\"\n",
    "print(os.listdir(INPUT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CURATED_PATH = INPUT_FOLDER + \"train_curated.csv\"\n",
    "TRAIN_NOISY_PATH = INPUT_FOLDER + \"train_noisy.csv\"\n",
    "SAMPLE_SUBMISSION_PATH = INPUT_FOLDER + \"sample_submission.csv\"\n",
    "TRAIN_CURATED = INPUT_FOLDER + \"train_curated/\"\n",
    "TRAIN_NOISY = INPUT_FOLDER + \"train_noisy/\"\n",
    "TEST = INPUT_FOLDER + \"test/\"\n",
    "\n",
    "train_curated = pd.read_csv(TRAIN_CURATED_PATH)\n",
    "train_noisy = pd.read_csv(TRAIN_NOISY_PATH)\n",
    "sample = pd.read_csv(SAMPLE_SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, src_dict):\n",
    "    ar = np.zeros([len(labels), len(src_dict)])\n",
    "    for i, label in enumerate(labels):\n",
    "        label_list = label.split(',')\n",
    "        for la in label_list:\n",
    "            ar[i, src_dict[la]] = 1\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = sample.columns[1:]\n",
    "num_targets = len(target_names)\n",
    "\n",
    "src_dict = {target_names[i]:i for i in range(num_targets)}\n",
    "src_dict_inv = {i:target_names[i] for i in range(num_targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq = 128\n",
    "len_div = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_curated = train_curated['fname'].values\n",
    "labels = one_hot(train_curated['labels'], src_dict)\n",
    "\n",
    "fname_train,fname_val, labels_train, labels_val = train_test_split(fname_curated, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(fnames, labels, pickle_name, folder, num_freq=num_freq, len_div=len_div, div=2000):\n",
    "    num_batch = len(fnames) // div\n",
    "    rest = len(fnames) % div\n",
    "\n",
    "    pos = [range(div*k, div*(k+1)) for k in range(num_batch)]\n",
    "    pos.append(range(div*num_batch, div*num_batch+rest))\n",
    "\n",
    "    for k in range(num_batch+1):    \n",
    "        X_proc_ = np.zeros([1, num_freq, len_div])\n",
    "        y_proc_ = np.zeros([1,80])\n",
    "        for i, file in enumerate(fnames[pos[k]]):\n",
    "            wavfile = folder + file\n",
    "            y_proc, sr = librosa.load(wavfile)\n",
    "            S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "            log_S = librosa.power_to_db(S, ref=np.max)\n",
    "            X_proc = (log_S + 80) / 40 - 1\n",
    "\n",
    "            num_div = X_proc.shape[1] // len_div\n",
    "            num_pad = len_div - X_proc.shape[1] % len_div\n",
    "            redidual_amp = np.zeros([num_freq, num_pad])\n",
    "            dum = np.hstack([X_proc, redidual_amp])\n",
    "            X_proc_ = np.vstack([X_proc_, np.array(np.split(dum, num_div+1,1))])\n",
    "            for _ in range(num_div+1):\n",
    "                y_proc_ = np.vstack([y_proc_, labels[i+div*k]])\n",
    "\n",
    "        X = X_proc_[1:]\n",
    "        y = y_proc_[1:]\n",
    "        X = X.reshape([-1, num_freq, len_div, 1])\n",
    "        print('iter No.{} is done.'.format(k))\n",
    "        with open('preprocessed_dataset/{}_{}.pickle'.format(pickle_name, k), 'wb') as f:\n",
    "            pickle.dump(X, f)\n",
    "            pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter No.0 is done.\n",
      "iter No.1 is done.\n"
     ]
    }
   ],
   "source": [
    "process(fname_train, labels_train, pickle_name='train_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process(fname_val, labels_val, pickle_name='val_arr', folder=TRAIN_CURATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_noisy = train_noisy['fname'].values\n",
    "label_noisy = one_hot(train_noisy['labels'], src_dict)\n",
    "\n",
    "fname_noisy_train,fname_noisy_val, labels_noisy_train, labels_noisy_val = train_test_split(fname_noisy, label_noisy, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter No.0 is done.\n",
      "iter No.1 is done.\n",
      "iter No.2 is done.\n",
      "iter No.3 is done.\n",
      "iter No.4 is done.\n",
      "iter No.5 is done.\n",
      "iter No.6 is done.\n",
      "iter No.7 is done.\n"
     ]
    }
   ],
   "source": [
    "process(fname_noisy_train, labels_noisy_train, pickle_name='noisy_train_arr', folder=TRAIN_NOISY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process(fname_noisy_val, labels_noisy_val, pickle_name='noisy_val_arr', folder=TRAIN_NOISY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter No.0 is done.\n",
      "iter No.1 is done.\n",
      "iter No.2 is done.\n",
      "iter No.3 is done.\n"
     ]
    }
   ],
   "source": [
    "div = 300\n",
    "num_batch = len(file_name) // div\n",
    "rest = len(file_name) % div\n",
    "\n",
    "pos = [range(div*k, div*(k+1)) for k in range(num_batch)]\n",
    "pos.append(range(div*num_batch, div*num_batch+rest))\n",
    "\n",
    "for k in range(num_batch+1):\n",
    "    X_proc_ = []\n",
    "    for file in file_name[pos[k]]:\n",
    "        wavfile = file\n",
    "        y_proc, sr = librosa.load(wavfile)\n",
    "        S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "        X_proc = (log_S + 80) / 40 - 1\n",
    "\n",
    "        num_div = X_proc.shape[1] // len_div\n",
    "        num_pad = len_div - X_proc.shape[1] % len_div\n",
    "        redidual_amp = np.zeros([num_freq, num_pad])\n",
    "        dum = np.hstack([X_proc, redidual_amp])\n",
    "        X_proc_.append(np.array(np.split(dum, num_div+1,1)))\n",
    "    \n",
    "    print('iter No.{} is done.'.format(k))\n",
    "\n",
    "    with open('out/test_arr_{}.pickle'.format(k), 'wb') as f:\n",
    "        pickle.dump(X_proc_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_ = []\n",
    "\n",
    "for k in range(num_batch+1):\n",
    "    with open('out/test_arr_{}.pickle'.format(k), 'rb') as f:\n",
    "        X_part = pickle.load(f)\n",
    "    X_proc_.extend(X_part)\n",
    "    \n",
    "with open('test_arr.pickle', 'wb') as f:\n",
    "    pickle.dump(X_proc_, f)\n",
    "    pickle.dump(file_name, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_proc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_list = []\n",
    "\n",
    "for file in filename:\n",
    "    wavfile = file\n",
    "    y_proc, sr = librosa.load(wavfile)\n",
    "    S = librosa.feature.melspectrogram(y_proc, sr=sr, n_mels=num_freq)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    X_proc = (log_S + 80) / 40 - 1\n",
    "    \n",
    "    num_div = X_proc.shape[1] // len_div\n",
    "    num_pad = len_div - X_proc.shape[1] % len_div\n",
    "    redidual_amp = np.zeros([num_freq, num_pad])\n",
    "    dum = np.hstack([X_proc, redidual_amp])\n",
    "    X_test_list.append(np.array(np.split(dum, num_div+1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for X_test in X_test_list:\n",
    "    pred = model.predict(X_test.reshape([-1, num_freq, len_div,1])).sum(axis=0) / len(X_test)\n",
    "    pred_list.append(pred)\n",
    "y_pred = np.array(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_names = sample.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for f in filename:\n",
    "    names.append(f.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_file = pd.Series(names, name='fname')\n",
    "label = pd.DataFrame(y_pred, columns=sound_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.concat([se_file, label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
