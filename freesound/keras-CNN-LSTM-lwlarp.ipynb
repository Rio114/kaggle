{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split \n",
    "import librosa\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers.recurrent import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_curated.csv', 'train_noisy.csv', 'sample_submission.csv', 'train_noisy', 'train_curated', 'test']\n"
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = \"../../data_kaggle/freesound/input\"\n",
    "# INPUT_FOLDER = \"../input/\"\n",
    "print(os.listdir(INPUT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq = 128\n",
    "len_div = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_hidden = 300\n",
    "n_filter = 8\n",
    "\n",
    "conv_list = []\n",
    "\n",
    "inputs = Input(shape=(num_freq,len_div,1 ), name='input')\n",
    "\n",
    "conv1 = Conv2D(n_filter, (17, 1),activation='relu',padding='same',name='conv1')(inputs)\n",
    "pool1 = MaxPooling2D((17, 1),strides=(4, 1),padding='same',name='pool1')(conv1)\n",
    "norm1 = BatchNormalization(axis=-1, name='norm1')(pool1)\n",
    "reshape1 = Reshape([-1, len_div])(norm1)\n",
    "conv_list.append(reshape1)\n",
    "\n",
    "conv2 = Conv2D(n_filter, (11, 1),activation='relu',padding='same',name='conv2')(inputs)\n",
    "pool2 = MaxPooling2D((11, 1),strides=(2, 1),padding='same',name='pool2')(conv2)\n",
    "norm2 = BatchNormalization(axis=-1, name='norm2')(pool2)\n",
    "reshape2 = Reshape([-1, len_div])(norm2)\n",
    "conv_list.append(reshape2)\n",
    "\n",
    "conv3 = Conv2D(n_filter, (7, 1),activation='relu',padding='same',name='conv3')(inputs)\n",
    "pool3 = MaxPooling2D((7, 1),strides=(4, 1),padding='same',name='pool3')(conv3)\n",
    "norm3 = BatchNormalization(axis=-1, name='norm3')(pool3)\n",
    "reshape3 = Reshape([-1, len_div])(norm3)\n",
    "conv_list.append(reshape3)\n",
    "\n",
    "concat = concatenate(conv_list, name='concat', axis=1)\n",
    "\n",
    "lstm = LSTM(n_hidden, return_sequences=False, name='LSTM')(concat)\n",
    "drop = Dropout(rate=0.05)(lstm)\n",
    "dense = Dense(80, name='dense1')(drop)\n",
    "pred = Activation('softmax',name='pred')(dense)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 128, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 256, 8)  144         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 256, 8)  64          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 256, 8)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 32, 256, 8)   0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "norm1 (BatchNormalization)      (None, 32, 256, 8)   32          pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "norm3 (BatchNormalization)      (None, 32, 256, 8)   32          pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 256, 256)     0           norm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 256, 256)     0           norm3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 512, 256)     0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, 300)          668400      concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 80)           24080       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pred (Activation)               (None, 80)           0           dense1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 692,752\n",
      "Trainable params: 692,720\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    \n",
    "    # find true labels\n",
    "    pos_class_indices = tf.where(y_true > 0) \n",
    "    \n",
    "    # put rank on each element\n",
    "    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n",
    "    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n",
    "    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n",
    "    sample_range = tf.transpose(sample_range)\n",
    "    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n",
    "    retrieved_class_map = tf.transpose(retrieved_class_map)\n",
    "    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n",
    "    \n",
    "    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n",
    "    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n",
    "    \n",
    "    class_rankings = tf.scatter_nd(retrieved_class_map,\n",
    "                                          class_range,\n",
    "                                          tf.shape(y_pred))\n",
    "    \n",
    "    #pick_up ranks\n",
    "    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n",
    "\n",
    "    # add one for division for \"presicion_at_hits\"\n",
    "    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n",
    "    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n",
    "    \n",
    "    # generate tensor [num_sample, predict_rank], \n",
    "    # top-N predicted elements have flag, N is the number of positive for each sample.\n",
    "    sample_label = pos_class_indices[:, 0]   \n",
    "    sample_label = tf.reshape(sample_label, (-1, 1))\n",
    "    sample_label = tf.cast(sample_label, tf.int32)\n",
    "    \n",
    "    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n",
    "    retrieved_class_true_position = tf.concat((sample_label, \n",
    "                                               num_correct_until_correct), axis=1)\n",
    "    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n",
    "    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n",
    "                                         retrieved_pos, \n",
    "                                         tf.shape(y_pred))\n",
    "    # cumulate predict_rank\n",
    "    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n",
    "\n",
    "    # find positive position\n",
    "    pos_ret_indices = tf.where(retrieved_class_true > 0)\n",
    "\n",
    "    # find cumulative hits\n",
    "    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n",
    "    correct_rank = tf.cast(correct_rank, tf.float32)\n",
    "\n",
    "    # compute presicion\n",
    "    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n",
    "\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "def tf_lwlrap(y_true, y_pred):\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n",
    "    pos_flgs = tf.cast(y_true > 0, tf.int32)\n",
    "    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n",
    "    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n",
    "                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n",
    "    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n",
    "    class_label = pos_class_indices[:,1]\n",
    "    sum_precisions_by_classes = tf.unsorted_segment_sum(precision_at_hits,\n",
    "                                                        class_label,\n",
    "                                                       num_classes)\n",
    "    labels_per_class = tf.cast(labels_per_class, tf.float32)\n",
    "    labels_per_class = tf.add(labels_per_class, 1e-7)\n",
    "    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n",
    "                                  tf.cast(labels_per_class, tf.float32))\n",
    "    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf_lwlrap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "           rotation_range=0,\n",
    "           width_shift_range=64,\n",
    "           height_shift_range=0,\n",
    "           shear_range=0,\n",
    "           zoom_range=0,\n",
    "           horizontal_flip=False,\n",
    "           vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch No.0\n",
      "learning with curated data\n",
      "Train on 7550 samples, validate on 1827 samples\n",
      "Epoch 1/2\n",
      "7550/7550 [==============================] - 135s 18ms/step - loss: 4.8790 - tf_lwlrap: 0.1407 - val_loss: 4.6542 - val_tf_lwlrap: 0.1525\n",
      "Epoch 2/2\n",
      "7550/7550 [==============================] - 131s 17ms/step - loss: 4.6630 - tf_lwlrap: 0.1859 - val_loss: 4.5414 - val_tf_lwlrap: 0.1849\n",
      "learning with noisy data No.0\n",
      "Train on 5878 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5878/5878 [==============================] - 126s 21ms/step - loss: 5.3208 - tf_lwlrap: 0.1185 - val_loss: 5.0753 - val_tf_lwlrap: 0.1167\n",
      "Epoch 2/2\n",
      "5878/5878 [==============================] - 126s 21ms/step - loss: 5.1480 - tf_lwlrap: 0.1493 - val_loss: 4.9989 - val_tf_lwlrap: 0.1371\n",
      "learning with noisy data No.1\n",
      "Train on 5856 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5856/5856 [==============================] - 124s 21ms/step - loss: 5.0274 - tf_lwlrap: 0.1633 - val_loss: 4.9876 - val_tf_lwlrap: 0.1462\n",
      "Epoch 2/2\n",
      "5856/5856 [==============================] - 125s 21ms/step - loss: 4.9073 - tf_lwlrap: 0.1913 - val_loss: 4.8985 - val_tf_lwlrap: 0.1608\n",
      "learning with noisy data No.2\n",
      "Train on 5888 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5888/5888 [==============================] - 125s 21ms/step - loss: 4.9491 - tf_lwlrap: 0.1664 - val_loss: 4.8062 - val_tf_lwlrap: 0.1731\n",
      "Epoch 2/2\n",
      "5888/5888 [==============================] - 125s 21ms/step - loss: 4.8219 - tf_lwlrap: 0.1950 - val_loss: 4.7540 - val_tf_lwlrap: 0.1870\n",
      "learning with noisy data No.3\n",
      "Train on 5429 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5429/5429 [==============================] - 118s 22ms/step - loss: 4.8598 - tf_lwlrap: 0.1839 - val_loss: 4.7168 - val_tf_lwlrap: 0.1836\n",
      "Epoch 2/2\n",
      "5429/5429 [==============================] - 118s 22ms/step - loss: 4.7344 - tf_lwlrap: 0.2116 - val_loss: 4.6681 - val_tf_lwlrap: 0.1988\n",
      "learning with noisy data No.4\n",
      "Train on 5871 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5871/5871 [==============================] - 125s 21ms/step - loss: 4.8257 - tf_lwlrap: 0.2196 - val_loss: 4.6301 - val_tf_lwlrap: 0.2031\n",
      "Epoch 2/2\n",
      "5871/5871 [==============================] - 125s 21ms/step - loss: 4.7079 - tf_lwlrap: 0.2400 - val_loss: 4.5965 - val_tf_lwlrap: 0.2076\n",
      "learning with noisy data No.5\n",
      "Train on 5899 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5899/5899 [==============================] - 127s 21ms/step - loss: 4.6583 - tf_lwlrap: 0.2263 - val_loss: 4.5357 - val_tf_lwlrap: 0.2204\n",
      "Epoch 2/2\n",
      "5899/5899 [==============================] - 126s 21ms/step - loss: 4.5498 - tf_lwlrap: 0.2491 - val_loss: 4.5165 - val_tf_lwlrap: 0.2274\n",
      "learning with noisy data No.6\n",
      "Train on 5872 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.5722 - tf_lwlrap: 0.2271 - val_loss: 4.5705 - val_tf_lwlrap: 0.2161\n",
      "Epoch 2/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.4873 - tf_lwlrap: 0.2456 - val_loss: 4.5432 - val_tf_lwlrap: 0.2191\n",
      "learning with noisy data No.7\n",
      "Train on 5872 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.6590 - tf_lwlrap: 0.2461 - val_loss: 4.5039 - val_tf_lwlrap: 0.2274\n",
      "Epoch 2/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.5295 - tf_lwlrap: 0.2777 - val_loss: 4.5008 - val_tf_lwlrap: 0.2288\n",
      "epoch No.1\n",
      "learning with curated data\n",
      "Train on 7550 samples, validate on 1827 samples\n",
      "Epoch 1/2\n",
      "7550/7550 [==============================] - 131s 17ms/step - loss: 4.4521 - tf_lwlrap: 0.2399 - val_loss: 4.1419 - val_tf_lwlrap: 0.2618\n",
      "Epoch 2/2\n",
      "7550/7550 [==============================] - 132s 17ms/step - loss: 4.1411 - tf_lwlrap: 0.2968 - val_loss: 3.9702 - val_tf_lwlrap: 0.3103\n",
      "learning with noisy data No.0\n",
      "Train on 5899 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5899/5899 [==============================] - 126s 21ms/step - loss: 4.6481 - tf_lwlrap: 0.2362 - val_loss: 4.5108 - val_tf_lwlrap: 0.2300\n",
      "Epoch 2/2\n",
      "5899/5899 [==============================] - 126s 21ms/step - loss: 4.4371 - tf_lwlrap: 0.2729 - val_loss: 4.4681 - val_tf_lwlrap: 0.2307\n",
      "learning with noisy data No.1\n",
      "Train on 5856 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5856/5856 [==============================] - 125s 21ms/step - loss: 4.4939 - tf_lwlrap: 0.2689 - val_loss: 4.4391 - val_tf_lwlrap: 0.2453\n",
      "Epoch 2/2\n",
      "5856/5856 [==============================] - 124s 21ms/step - loss: 4.3586 - tf_lwlrap: 0.2973 - val_loss: 4.4725 - val_tf_lwlrap: 0.2337\n",
      "learning with noisy data No.2\n",
      "Train on 5878 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5878/5878 [==============================] - 125s 21ms/step - loss: 4.5030 - tf_lwlrap: 0.2689 - val_loss: 4.4037 - val_tf_lwlrap: 0.2551\n",
      "Epoch 2/2\n",
      "5878/5878 [==============================] - 125s 21ms/step - loss: 4.3985 - tf_lwlrap: 0.2956 - val_loss: 4.4141 - val_tf_lwlrap: 0.2518\n",
      "learning with noisy data No.3\n",
      "Train on 5872 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 126s 21ms/step - loss: 4.4667 - tf_lwlrap: 0.2913 - val_loss: 4.3283 - val_tf_lwlrap: 0.2604\n",
      "Epoch 2/2\n",
      "5872/5872 [==============================] - 126s 21ms/step - loss: 4.3554 - tf_lwlrap: 0.3172 - val_loss: 4.3263 - val_tf_lwlrap: 0.2600\n",
      "learning with noisy data No.4\n",
      "Train on 5871 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5871/5871 [==============================] - 125s 21ms/step - loss: 4.4769 - tf_lwlrap: 0.2882 - val_loss: 4.3502 - val_tf_lwlrap: 0.2664\n",
      "Epoch 2/2\n",
      "5871/5871 [==============================] - 125s 21ms/step - loss: 4.3624 - tf_lwlrap: 0.3157 - val_loss: 4.3520 - val_tf_lwlrap: 0.2626\n",
      "learning with noisy data No.5\n",
      "Train on 5872 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 126s 21ms/step - loss: 4.3268 - tf_lwlrap: 0.2828 - val_loss: 4.2737 - val_tf_lwlrap: 0.2740\n",
      "Epoch 2/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.1951 - tf_lwlrap: 0.3177 - val_loss: 4.2956 - val_tf_lwlrap: 0.2671\n",
      "learning with noisy data No.6\n",
      "Train on 5888 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5888/5888 [==============================] - 126s 21ms/step - loss: 4.3496 - tf_lwlrap: 0.2829 - val_loss: 4.2654 - val_tf_lwlrap: 0.2823\n",
      "Epoch 2/2\n",
      "5888/5888 [==============================] - 126s 21ms/step - loss: 4.2325 - tf_lwlrap: 0.3081 - val_loss: 4.2451 - val_tf_lwlrap: 0.2912\n",
      "learning with noisy data No.7\n",
      "Train on 5429 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5429/5429 [==============================] - 119s 22ms/step - loss: 4.3738 - tf_lwlrap: 0.2898 - val_loss: 4.3077 - val_tf_lwlrap: 0.2642\n",
      "Epoch 2/2\n",
      "5429/5429 [==============================] - 118s 22ms/step - loss: 4.2637 - tf_lwlrap: 0.3153 - val_loss: 4.2243 - val_tf_lwlrap: 0.2889\n",
      "epoch No.2\n",
      "learning with curated data\n",
      "Train on 7550 samples, validate on 1827 samples\n",
      "Epoch 1/2\n",
      "7550/7550 [==============================] - 131s 17ms/step - loss: 4.2444 - tf_lwlrap: 0.2812 - val_loss: 3.9182 - val_tf_lwlrap: 0.3160\n",
      "Epoch 2/2\n",
      "7550/7550 [==============================] - 132s 17ms/step - loss: 3.9367 - tf_lwlrap: 0.3502 - val_loss: 3.8164 - val_tf_lwlrap: 0.3403\n",
      "learning with noisy data No.0\n",
      "Train on 5899 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5899/5899 [==============================] - 125s 21ms/step - loss: 4.4818 - tf_lwlrap: 0.2763 - val_loss: 4.3385 - val_tf_lwlrap: 0.2721\n",
      "Epoch 2/2\n",
      "5899/5899 [==============================] - 125s 21ms/step - loss: 4.2390 - tf_lwlrap: 0.3203 - val_loss: 4.3045 - val_tf_lwlrap: 0.2760\n",
      "learning with noisy data No.1\n",
      "Train on 5856 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5856/5856 [==============================] - 125s 21ms/step - loss: 4.2560 - tf_lwlrap: 0.3214 - val_loss: 4.2304 - val_tf_lwlrap: 0.2829\n",
      "Epoch 2/2\n",
      "5856/5856 [==============================] - 125s 21ms/step - loss: 4.1433 - tf_lwlrap: 0.3441 - val_loss: 4.2279 - val_tf_lwlrap: 0.2856\n",
      "learning with noisy data No.2\n",
      "Train on 5872 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 126s 21ms/step - loss: 4.2109 - tf_lwlrap: 0.3108 - val_loss: 4.2702 - val_tf_lwlrap: 0.2775\n",
      "Epoch 2/2\n",
      "5872/5872 [==============================] - 125s 21ms/step - loss: 4.0882 - tf_lwlrap: 0.3342 - val_loss: 4.2719 - val_tf_lwlrap: 0.2876\n",
      "learning with noisy data No.3\n",
      "Train on 5871 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5871/5871 [==============================] - 125s 21ms/step - loss: 4.3291 - tf_lwlrap: 0.3216 - val_loss: 4.2353 - val_tf_lwlrap: 0.2872\n",
      "Epoch 2/2\n",
      "5871/5871 [==============================] - 128s 22ms/step - loss: 4.1886 - tf_lwlrap: 0.3543 - val_loss: 4.2248 - val_tf_lwlrap: 0.2963\n",
      "learning with noisy data No.4\n",
      "Train on 5878 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5878/5878 [==============================] - 127s 22ms/step - loss: 4.2782 - tf_lwlrap: 0.3192 - val_loss: 4.1792 - val_tf_lwlrap: 0.3002\n",
      "Epoch 2/2\n",
      "5878/5878 [==============================] - 127s 22ms/step - loss: 4.1468 - tf_lwlrap: 0.3533 - val_loss: 4.1627 - val_tf_lwlrap: 0.3017\n",
      "learning with noisy data No.5\n",
      "Train on 5888 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5888/5888 [==============================] - 127s 22ms/step - loss: 4.1679 - tf_lwlrap: 0.3218 - val_loss: 4.1989 - val_tf_lwlrap: 0.2920\n",
      "Epoch 2/2\n",
      "5888/5888 [==============================] - 127s 22ms/step - loss: 4.0488 - tf_lwlrap: 0.3466 - val_loss: 4.2196 - val_tf_lwlrap: 0.2913\n",
      "learning with noisy data No.6\n",
      "Train on 5429 samples, validate on 5866 samples\n",
      "Epoch 1/2\n",
      "5429/5429 [==============================] - 121s 22ms/step - loss: 4.2283 - tf_lwlrap: 0.3199 - val_loss: 4.1244 - val_tf_lwlrap: 0.3043\n",
      "Epoch 2/2\n",
      "5429/5429 [==============================] - 119s 22ms/step - loss: 4.0934 - tf_lwlrap: 0.3523 - val_loss: 4.1318 - val_tf_lwlrap: 0.2994\n",
      "learning with noisy data No.7\n",
      "Train on 5872 samples, validate on 5750 samples\n",
      "Epoch 1/2\n",
      "5872/5872 [==============================] - 124s 21ms/step - loss: 4.2758 - tf_lwlrap: 0.3343 - val_loss: 4.1721 - val_tf_lwlrap: 0.3071\n",
      "Epoch 2/2\n",
      "3680/5872 [=================>............] - ETA: 35s - loss: 4.1358 - tf_lwlrap: 0.3729"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ef910092725b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                   validation_data=(X_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python/kaggle/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 20\n",
    "for n in range(epochs):\n",
    "    print('epoch No.{}'.format(n))\n",
    "    print('learning with curated data')\n",
    "    with open('preprocessed_dataset/train_arr_0.pickle', 'rb') as f:\n",
    "        X_train0 = pickle.load(f)\n",
    "        y_train0 = pickle.load(f)\n",
    "    with open('preprocessed_dataset/train_arr_1.pickle', 'rb') as f:\n",
    "        X_train1 = pickle.load(f)\n",
    "        y_train1 = pickle.load(f)\n",
    "    X_train = np.vstack([X_train0, X_train1])\n",
    "    y_train = np.vstack([y_train0, y_train1])\n",
    "    \n",
    "    with open('preprocessed_dataset/val_arr_0.pickle', 'rb') as f:\n",
    "        X_val0 = pickle.load(f)\n",
    "        y_val0 = pickle.load(f)\n",
    "    with open('preprocessed_dataset/val_arr_1.pickle', 'rb') as f:\n",
    "        X_val1 = pickle.load(f)\n",
    "        y_val1 = pickle.load(f)\n",
    "    X_val = np.vstack([X_val0, X_val1])\n",
    "    y_val = np.vstack([y_val0, y_val1])\n",
    "     \n",
    "    model.fit(X_train, y_train,batch_size=batch_size,epochs=2,validation_data=(X_val, y_val))    \n",
    "    \n",
    "    pick = random.sample(range(8),8)\n",
    "    for i, m in enumerate(pick):\n",
    "        print('learning with noisy data No.{}'.format(i))\n",
    "        with open('preprocessed_dataset/noisy_train_arr_{}.pickle'.format(m), 'rb') as f:\n",
    "            X_train = pickle.load(f)\n",
    "            y_train = pickle.load(f)\n",
    "        pick_val = random.sample(range(2),1)[0]\n",
    "        with open('preprocessed_dataset/noisy_val_arr_{}.pickle'.format(pick_val), 'rb') as f:\n",
    "            X_val = pickle.load(f)\n",
    "            y_val = pickle.load(f)\n",
    "        model.fit(X_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=2,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('20190511-2model.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
