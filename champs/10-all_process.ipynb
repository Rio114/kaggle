{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from multiprocessing import Process, Pool\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from process import type_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pred(df_pred_idx, df_map_idx, m, target_cols='predict'):\n",
    "    ids = df_pred_idx.loc[m]['id'].values\n",
    "    preds = df_pred_idx.loc[m]['predict'].values\n",
    "    pred_dict = {ids[i]:preds[i] for i in range(ids.shape[0])}\n",
    "    pred_dict[-1] = 0\n",
    "    df_sc_train = df_map_idx.loc[m][df_map_idx.columns[:-1]].replace(pred_dict)\n",
    "    df_sc_train['id'] = df_map_idx.loc[m]['id']\n",
    "    return df_sc_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../../data_kaggle/champs/'\n",
    "OUTPUT = FOLDER + 'out/'\n",
    "TEMP = OUTPUT + 'temp/'\n",
    "MAP  = OUTPUT + 'map/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input\n",
    "df_train = pd.read_csv(FOLDER+'train.csv')\n",
    "df_test = pd.read_csv(FOLDER+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DATE = '20190721'\n",
    "MAP_DATE = '20190728'\n",
    "MODEL_DATE = '20190808'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed input\n",
    "map_train = MAP + MAP_DATE + '_' + 'map_train.pickle'\n",
    "map_test = MAP + MAP_DATE + '_' + 'map_test.pickle'\n",
    "dist_train = MAP + MAP_DATE + '_' + 'dist_train.pickle'\n",
    "dist_test = MAP + MAP_DATE + '_' + 'dist_test.pickle'\n",
    "mols_split = OUTPUT + MODEL_DATE + '_' + 'molecule_name_split.pickle'\n",
    "\n",
    "first_train = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_train_{}.pickle'#.format(b)\n",
    "first_test = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_test_{}.pickle'#.format(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "pred_train = OUTPUT + MODEL_DATE +  '_' + 'pred_train_{}.pickle'#.format(num_rep)\n",
    "pred_test = OUTPUT + MODEL_DATE + '_' + 'submission_{}.csv'#.format(num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output files\n",
    "pred_dist_train = OUTPUT + MODEL_DATE  + '_' + 'pred_dist_train.pickle'\n",
    "pred_dist_test = OUTPUT + MODEL_DATE  + '_' + 'pred_dist_test.pickle'\n",
    "\n",
    "features_train = OUTPUT + MODEL_DATE  + '_' + 'features_train_{}.pickle'#.format(b)\n",
    "features_test = OUTPUT + MODEL_DATE  + '_' + 'features_test_{}.pickle'#.format(b)\n",
    "\n",
    "trained_models = OUTPUT + MAP_DATE + '_' + 'champs_models_lgb_{}_{}.pickle'#.format(b, num_rep)\n",
    "\n",
    "pred_train_temp = TEMP + 'pred_train_{}.pickle'\n",
    "pred_test_temp = TEMP + 'submission_{}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 50000\n",
    "params = {\n",
    "        'task' : 'train',\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'objective' : 'regression',\n",
    "        'metric' : {'l1'},\n",
    "        'num_leaves' : 255,\n",
    "        'learning_rate' : 0.0001,\n",
    "        'feature_fraction' : 0.8,\n",
    "    'seed':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_types = ['3JHN', '3JHC','1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_div = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     df_pred_dist_train.to_pickle(pred_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train models\n",
      "---------- 3JHN ----------\n",
      "50000\n",
      "score first model(train): -4.93\n",
      "score second model(train): -3.80\n",
      "score first model(val): -2.25\n",
      "score second model(val): -2.21\n",
      "elapsed_time:6600.33[sec]\n",
      "---------- 3JHC ----------\n"
     ]
    }
   ],
   "source": [
    "for num_rep in range(2, 10):\n",
    "    print('repeat number:', num_rep)\n",
    "\n",
    "    # prepare data\n",
    "    print('prepare data')\n",
    "    start = time.time()\n",
    "    mols_train = df_train['molecule_name'].unique()\n",
    "    df_pred_train = pd.read_pickle(pred_train.format(num_rep))\n",
    "    df_pred_train = df_pred_train.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_train_idx = pd.merge(df_train, df_pred_train, on=['id']).set_index('molecule_name')\n",
    "    df_map_train_idx = pd.read_pickle(map_train).set_index('molecule_name')\n",
    "    df_dist_train_idx = pd.read_pickle(dist_train).set_index('molecule_name')\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    # map train-data\n",
    "    print('map train-data')\n",
    "    # map train-data\n",
    "    def map_train_data(temp_no):\n",
    "        df_map_pred_train = pd.DataFrame()\n",
    "        # for m in mols_train[:10]:\n",
    "        div = len(mols_train) // num_div\n",
    "        res = len(mols_train) % num_div\n",
    "\n",
    "        if temp_no == num_div - 1:\n",
    "            last_slice = div*(temp_no+1) + res\n",
    "        else:\n",
    "            last_slice = div*(temp_no+1)\n",
    "\n",
    "    #     for m in mols_train[div*temp_no:div*temp_no+100]:\n",
    "        for m in mols_train[div*temp_no:last_slice]:\n",
    "            if m == mols_train[2]:\n",
    "                continue\n",
    "            df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n",
    "            df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "\n",
    "        if temp_no == 0:\n",
    "            m = mols_train[2]\n",
    "            se_temp = pd.Series()\n",
    "        #     se_temp['molecule_name']  = m\n",
    "            se_temp['0'] = df_pred_train_idx.loc[m]['predict']\n",
    "            for i in range(48):\n",
    "                se_temp['{}'.format(i+1)] = 0.0\n",
    "            cols = df_map_pred_train_temp.columns[:-1]\n",
    "            df_map_pred_train_temp = pd.DataFrame(se_temp).T\n",
    "            df_map_pred_train_temp.columns = cols\n",
    "            df_map_pred_train_temp['id'] = df_pred_train_idx.loc[m]['id']\n",
    "            df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "        return pd.merge(df_map_pred_train, df_dist_train_idx, on=['id'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=num_div) as p:\n",
    "        df_pred_dist_train_list = p.map(map_train_data, [i for i in range(num_div)])\n",
    "#         p.join()\n",
    "    df_pred_dist_train = pd.concat(df_pred_dist_train_list, axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "    \n",
    "    df_pred_dist_train.to_pickle(pred_dist_train)\n",
    "    del df_dist_train_idx, df_pred_train_idx, df_map_train_idx\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('merge features_train')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        df_train_b = pd.read_pickle(first_train.format(b))\n",
    "        df_feature_train = pd.merge(df_train_b, df_pred_dist_train, on=['id'])\n",
    "        df_feature_train.to_pickle(features_train.format(b))\n",
    "        del df_feature_train, df_train_b\n",
    "        gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('train models')\n",
    "    start = time.time()\n",
    "    scores = []\n",
    "    with open(mols_split, 'rb') as f:\n",
    "        mols_train = pickle.load(f)\n",
    "        mols_val =  pickle.load(f)\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "\n",
    "        df = pd.read_pickle(features_train.format(b)).fillna(0)\n",
    "\n",
    "        df_train = df[df['molecule_name'].isin(mols_train)]    \n",
    "        y_train = df_train['scalar_coupling_constant'].values\n",
    "        X_train = df_train[df_train.columns[6:]].values\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "        df_val = df[df['molecule_name'].isin(mols_val)]\n",
    "        y_val = df_val['scalar_coupling_constant'].values\n",
    "        X_val = df_val[df_val.columns[6:]].values\n",
    "        lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                verbose_eval=0,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=50)\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'wb') as f:\n",
    "            pickle.dump(gbm, f)\n",
    "\n",
    "        y_pred_train = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
    "        y_pred_val = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "\n",
    "#         df_pred_train = pd.DataFrame([df_train['id'], y_pred_train], index=['id', 'scalar_coupling_constant']).T\n",
    "#         df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "#         df_pred_val = pd.DataFrame([df_val['id'], y_pred_val], index=['id', 'scalar_coupling_constant']).T\n",
    "#         df_pred_val['id'] = df_pred_val['id'].astype('int32')    \n",
    "        \n",
    "        y_pred = gbm.predict(df[df.columns[6:]].values, num_iteration=gbm.best_iteration)\n",
    "        df_pred = pd.DataFrame([df['id'], y_pred], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred['id'] = df_pred['id'].astype('int32')\n",
    "        \n",
    "#         df_pred = pd.concat([df_pred_train, df_pred_val], axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "        \n",
    "        df_pred.to_pickle(pred_train_temp.format(b))\n",
    "\n",
    "        score_first_train = type_score(y_train, X_train[:, -98])\n",
    "        score_second_train = type_score(y_train, y_pred_train)\n",
    "\n",
    "        score_first = type_score(y_val, X_val[:, -98])\n",
    "        score_second = type_score(y_val, y_pred_val)\n",
    "        scores.append(score_second)\n",
    "        print(gbm.best_iteration)\n",
    "        print(\"score first model(train): %.2f\" %  (score_first_train))\n",
    "        print(\"score second model(train): %.2f\" %  (score_second_train))\n",
    "        print(\"score first model(val): %.2f\" %  (score_first))\n",
    "        print(\"score second model(val): %.2f\" %  (score_second))\n",
    "        elapsed_time = time.time() - start\n",
    "        print (\"elapsed_time:%.2f\" % elapsed_time + \"[sec]\")\n",
    "    print('total score:', np.array(scores).mean())\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('merge prediction')\n",
    "    start = time.time()\n",
    "    df_pred_train = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_b = pd.read_pickle(pred_train_temp.format(b))\n",
    "        df_pred_train = pd.concat([df_pred_train, df_b], axis=0, sort=False)\n",
    "\n",
    "    df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "    df_pred_train = df_pred_train.sort_values('id').reset_index(drop=True)\n",
    "    df_pred_train.to_pickle(pred_train.format(num_rep+1))\n",
    "    del df_pred_train, df_b\n",
    "    gc.collect()\n",
    "\n",
    "    # prepara test data\n",
    "    print('prepare test data')\n",
    "    start = time.time()\n",
    "    mols_test = df_test['molecule_name'].unique()\n",
    "    df_pred_test = pd.read_csv(pred_test.format(num_rep))\n",
    "    df_pred_test = df_pred_test.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_test_idx = pd.merge(df_test, df_pred_test, on=['id']).set_index('molecule_name')\n",
    "    df_map_test_idx = pd.read_pickle(map_test).set_index('molecule_name')\n",
    "    df_dist_test_idx = pd.read_pickle(dist_test).set_index('molecule_name')\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    # map test-data\n",
    "    print('map test-data')\n",
    "    \n",
    "    def map_test_data(temp_no):    \n",
    "        div = len(mols_test) // num_div\n",
    "        res = len(mols_test) % num_div\n",
    "        if temp_no == num_div - 1:\n",
    "            last_slice = div*(temp_no+1) + res\n",
    "        else:\n",
    "            last_slice = div*(temp_no+1)\n",
    "        df_map_pred_test = pd.DataFrame()\n",
    "        # for m in mols_test[:10]:\n",
    "        for m in mols_test[div*temp_no:last_slice]:\n",
    "            df_map_pred_test_temp = map_pred(df_pred_test_idx, df_map_test_idx, m)\n",
    "            df_map_pred_test = pd.concat([df_map_pred_test, df_map_pred_test_temp], axis=0, sort=False)\n",
    "        return pd.merge(df_map_pred_test, df_dist_test_idx, on=['id'])\n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=num_div) as p:\n",
    "        df_pred_dist_test_list = p.map(map_test_data, [i for i in range(num_div)])\n",
    "#         p.join()\n",
    "    df_pred_dist_test = pd.concat(df_pred_dist_test_list, axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "    df_pred_dist_test.to_pickle(pred_dist_test)\n",
    "    del df_map_test_idx, df_dist_test_idx, df_pred_test_idx, df_pred_test\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    print('merge features_test')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        df_test_b = pd.read_pickle(first_test.format(b))\n",
    "        df_feature_test = pd.merge(df_test_b, df_pred_dist_test, on=['id'])\n",
    "        df_feature_test.to_pickle(features_test.format(b))\n",
    "        del df_feature_test, df_test_b\n",
    "        gc.collect()\n",
    "    del df_pred_dist_test\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    print('get test prediction')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "        df_bond = pd.read_pickle(features_test.format(b))\n",
    "        y_pred_b =[]\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'rb') as f:\n",
    "            gbm = pickle.load(f)\n",
    "\n",
    "        X_test = df_bond[df_bond.columns[5:]].values  \n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "        df_pred = pd.DataFrame([df_bond['id'], y_pred], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred['id'] = df_pred['id'].astype('int32')\n",
    "        df_pred.to_pickle(pred_test_temp.format(b))\n",
    "        del df_pred, gbm, df_bond\n",
    "        gc.collect()\n",
    "\n",
    "    df_submit = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_submit_b = pd.read_pickle(pred_test_temp.format(b))\n",
    "        df_submit = pd.concat([df_submit, df_submit_b], axis=0)\n",
    "\n",
    "    df_submit['id'] = df_submit['id'].astype('int32')\n",
    "    df_submit = df_submit.sort_values('id').reset_index(drop=True)\n",
    "    df_submit.to_csv(pred_test.format(num_rep+1), index=False)\n",
    "    del df_submit, df_submit_b\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
