{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from multiprocessing import Process, Pool\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from process import type_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pred(df_pred_idx, df_map_idx, m, target_cols='predict'):\n",
    "    ids = df_pred_idx.loc[m]['id'].values\n",
    "    preds = df_pred_idx.loc[m]['predict'].values\n",
    "    pred_dict = {ids[i]:preds[i] for i in range(ids.shape[0])}\n",
    "    pred_dict[-1] = 0\n",
    "    df_sc_train = df_map_idx.loc[m][df_map_idx.columns[:-1]].replace(pred_dict)\n",
    "    df_sc_train['id'] = df_map_idx.loc[m]['id']\n",
    "    return df_sc_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../../data_kaggle/champs/'\n",
    "OUTPUT = FOLDER + 'out/'\n",
    "TEMP = OUTPUT + 'temp/'\n",
    "MAP  = OUTPUT + 'map/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input\n",
    "df_train = pd.read_csv(FOLDER+'train.csv')\n",
    "df_test = pd.read_csv(FOLDER+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DATE = '20190721'\n",
    "VER = '02'\n",
    "MAP_DATE = '20190728'\n",
    "MODEL_DATE = '20190804'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed input\n",
    "map_train = MAP + MAP_DATE + '_' + 'map_train.pickle'\n",
    "map_test = MAP + MAP_DATE + '_' + 'map_test.pickle'\n",
    "dist_train = MAP + MAP_DATE + '_' + 'dist_train.pickle'\n",
    "dist_test = MAP + MAP_DATE + '_' + 'dist_test.pickle'\n",
    "mols_split = OUTPUT + MODEL_DATE + '_' + 'molecule_name_split.pickle'\n",
    "\n",
    "first_train = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_train_{}.pickle'#.format(b)\n",
    "first_test = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_test_{}.pickle'#.format(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "pred_train = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'pred_train_{}.pickle'#.format(num_rep)\n",
    "pred_test = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'submission_{}.csv'#.format(num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output files\n",
    "pred_dist_train = OUTPUT + MODEL_DATE  + '_' + 'pred_dist_train.pickle'\n",
    "pred_dist_test = OUTPUT + MODEL_DATE  + '_' + 'pred_dist_test.pickle'\n",
    "\n",
    "features_train = OUTPUT + MODEL_DATE  + '_' + 'features_train_{}.pickle'#.format(b)\n",
    "features_test = OUTPUT + MODEL_DATE  + '_' + 'features_test_{}.pickle'#.format(b)\n",
    "\n",
    "trained_models = OUTPUT + MAP_DATE + '_' + 'champs_models_lgb_{}_{}.pickle'#.format(b, num_rep)\n",
    "\n",
    "pred_train_temp = TEMP + 'pred_train_{}.pickle'\n",
    "pred_test_temp = TEMP + 'submission_{}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 30000\n",
    "params = {\n",
    "        'task' : 'train',\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'objective' : 'regression',\n",
    "        'metric' : {'l1'},\n",
    "        'num_leaves' : 127,\n",
    "        'learning_rate' : 0.05,\n",
    "        'feature_fraction' : 0.8,\n",
    "    'seed':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_types = ['3JHN', '3JHC','1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_div = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     df_pred_dist_train.to_pickle(pred_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat number: 6\n",
      "prepare data\n",
      "total elapsed_time:3.6060397624969482[sec]\n",
      "map train-data\n",
      "total elapsed_time:984.9952185153961[sec]\n",
      "merge features_train\n",
      "total elapsed_time:57.84011888504028[sec]\n",
      "train models\n",
      "---------- 3JHN ----------\n",
      "1319\n",
      "score first model(train): -4.59\n",
      "score second model(train): -4.58\n",
      "score first model(val): -2.14\n",
      "score second model(val): -2.13\n",
      "elapsed_time:83.98[sec]\n",
      "---------- 3JHC ----------\n",
      "9517\n",
      "score first model(train): -2.98\n",
      "score second model(train): -3.28\n",
      "score first model(val): -1.45\n",
      "score second model(val): -1.45\n",
      "elapsed_time:1818.91[sec]\n",
      "---------- 1JHC ----------\n",
      "6403\n",
      "score first model(train): -2.29\n",
      "score second model(train): -2.44\n",
      "score first model(val): -0.63\n",
      "score second model(val): -0.63\n",
      "elapsed_time:644.81[sec]\n",
      "---------- 2JHH ----------\n",
      "5178\n",
      "score first model(train): -3.64\n",
      "score second model(train): -4.04\n",
      "score first model(val): -2.02\n",
      "score second model(val): -2.02\n",
      "elapsed_time:300.67[sec]\n",
      "---------- 1JHN ----------\n",
      "732\n",
      "score first model(train): -3.17\n",
      "score second model(train): -3.35\n",
      "score first model(val): -1.24\n",
      "score second model(val): -1.23\n",
      "elapsed_time:17.15[sec]\n",
      "---------- 2JHN ----------\n",
      "1817\n",
      "score first model(train): -4.02\n",
      "score second model(train): -4.16\n",
      "score first model(val): -1.83\n",
      "score second model(val): -1.83\n",
      "elapsed_time:61.30[sec]\n",
      "---------- 2JHC ----------\n",
      "6564\n",
      "score first model(train): -3.18\n",
      "score second model(train): -3.21\n",
      "score first model(val): -1.50\n",
      "score second model(val): -1.49\n",
      "elapsed_time:1024.10[sec]\n",
      "---------- 3JHH ----------\n",
      "5569\n",
      "score first model(train): -3.86\n",
      "score second model(train): -4.01\n",
      "score first model(val): -2.04\n",
      "score second model(val): -2.03\n",
      "elapsed_time:487.51[sec]\n",
      "total score: -1.6008285048850937\n",
      "total elapsed_time:487.5064685344696[sec]\n",
      "merge prediction\n",
      "prepare test data\n",
      "total elapsed_time:4.2001214027404785[sec]\n",
      "map test-data\n",
      "total elapsed_time:274.9503450393677[sec]\n",
      "merge features_test\n",
      "total elapsed_time:36.1668016910553[sec]\n",
      "get test prediction\n",
      "---------- 3JHN ----------\n",
      "---------- 3JHC ----------\n",
      "---------- 1JHC ----------\n",
      "---------- 2JHH ----------\n",
      "---------- 1JHN ----------\n",
      "---------- 2JHN ----------\n",
      "---------- 2JHC ----------\n",
      "---------- 3JHH ----------\n",
      "total elapsed_time:34.760738372802734[sec]\n",
      "repeat number: 7\n",
      "prepare data\n",
      "total elapsed_time:7.142240047454834[sec]\n",
      "map train-data\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-a909d359c946>\", line 34, in map_train_data\n    df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n  File \"<ipython-input-2-f8c2df87d0de>\", line 2, in map_pred\n    ids = df_pred_idx.loc[m]['id'].values\nAttributeError: 'numpy.int64' object has no attribute 'values'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a909d359c946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_div\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdf_pred_dist_train_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#         p.join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdf_pred_dist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pred_dist_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "for num_rep in range(6, 10):\n",
    "    print('repeat number:', num_rep)\n",
    "\n",
    "    # prepare data\n",
    "    print('prepare data')\n",
    "    start = time.time()\n",
    "    mols_train = df_train['molecule_name'].unique()\n",
    "    df_pred_train = pd.read_pickle(pred_train.format(num_rep))\n",
    "    df_pred_train = df_pred_train.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_train_idx = pd.merge(df_train, df_pred_train, on=['id']).set_index('molecule_name')\n",
    "    df_map_train_idx = pd.read_pickle(map_train).set_index('molecule_name')\n",
    "    df_dist_train_idx = pd.read_pickle(dist_train).set_index('molecule_name')\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    # map train-data\n",
    "    print('map train-data')\n",
    "    # map train-data\n",
    "    def map_train_data(temp_no):\n",
    "        df_map_pred_train = pd.DataFrame()\n",
    "        # for m in mols_train[:10]:\n",
    "        div = len(mols_train) // num_div\n",
    "        res = len(mols_train) % num_div\n",
    "\n",
    "        if temp_no == num_div - 1:\n",
    "            last_slice = div*(temp_no+1) + res\n",
    "        else:\n",
    "            last_slice = div*(temp_no+1)\n",
    "\n",
    "    #     for m in mols_train[div*temp_no:div*temp_no+100]:\n",
    "        for m in mols_train[div*temp_no:last_slice]:\n",
    "            if m == mols_train[2]:\n",
    "                continue\n",
    "            df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n",
    "            df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "\n",
    "        if temp_no == 0:\n",
    "            m = mols_train[2]\n",
    "            se_temp = pd.Series()\n",
    "        #     se_temp['molecule_name']  = m\n",
    "            se_temp['0'] = df_pred_train_idx.loc[m]['predict']\n",
    "            for i in range(48):\n",
    "                se_temp['{}'.format(i+1)] = 0.0\n",
    "            cols = df_map_pred_train_temp.columns[:-1]\n",
    "            df_map_pred_train_temp = pd.DataFrame(se_temp).T\n",
    "            df_map_pred_train_temp.columns = cols\n",
    "            df_map_pred_train_temp['id'] = df_pred_train_idx.loc[m]['id']\n",
    "            df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "        return pd.merge(df_map_pred_train, df_dist_train_idx, on=['id'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=num_div) as p:\n",
    "        df_pred_dist_train_list = p.map(map_train_data, [i for i in range(num_div)])\n",
    "#         p.join()\n",
    "    df_pred_dist_train = pd.concat(df_pred_dist_train_list, axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "    \n",
    "    df_pred_dist_train.to_pickle(pred_dist_train)\n",
    "    del df_dist_train_idx, df_pred_train_idx, df_map_train_idx\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('merge features_train')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        df_train_b = pd.read_pickle(first_train.format(b))\n",
    "        df_feature_train = pd.merge(df_train_b, df_pred_dist_train, on=['id'])\n",
    "        df_feature_train.to_pickle(features_train.format(b))\n",
    "        del df_feature_train, df_train_b\n",
    "        gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('train models')\n",
    "    start = time.time()\n",
    "    scores = []\n",
    "    with open(mols_split, 'rb') as f:\n",
    "        mols_train = pickle.load(f)\n",
    "        mols_val =  pickle.load(f)\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "\n",
    "        df = pd.read_pickle(features_train.format(b)).fillna(0)\n",
    "\n",
    "        df_train = df[df['molecule_name'].isin(mols_train)]    \n",
    "        y_train = df_train['scalar_coupling_constant'].values\n",
    "        X_train = df_train[df_train.columns[6:]].values\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "        df_val = df[df['molecule_name'].isin(mols_val)]\n",
    "        y_val = df_val['scalar_coupling_constant'].values\n",
    "        X_val = df_val[df_val.columns[6:]].values\n",
    "        lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                verbose_eval=0,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'wb') as f:\n",
    "            pickle.dump(gbm, f)\n",
    "\n",
    "        y_pred_train = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
    "        y_pred_val = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "\n",
    "#         df_pred_train = pd.DataFrame([df_train['id'], y_pred_train], index=['id', 'scalar_coupling_constant']).T\n",
    "#         df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "#         df_pred_val = pd.DataFrame([df_val['id'], y_pred_val], index=['id', 'scalar_coupling_constant']).T\n",
    "#         df_pred_val['id'] = df_pred_val['id'].astype('int32')    \n",
    "        \n",
    "        y_pred = gbm.predict(df[df.columns[6:]].values, num_iteration=gbm.best_iteration)\n",
    "        df_pred = pd.DataFrame([df['id'], y_pred], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred['id'] = df_pred['id'].astype('int32')\n",
    "        \n",
    "#         df_pred = pd.concat([df_pred_train, df_pred_val], axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "        \n",
    "        df_pred.to_pickle(pred_train_temp.format(b))\n",
    "\n",
    "        score_first_train = type_score(y_train, X_train[:, -98])\n",
    "        score_second_train = type_score(y_train, y_pred_train)\n",
    "\n",
    "        score_first = type_score(y_val, X_val[:, -98])\n",
    "        score_second = type_score(y_val, y_pred_val)\n",
    "        scores.append(score_second)\n",
    "        print(gbm.best_iteration)\n",
    "        print(\"score first model(train): %.2f\" %  (score_first_train))\n",
    "        print(\"score second model(train): %.2f\" %  (score_second_train))\n",
    "        print(\"score first model(val): %.2f\" %  (score_first))\n",
    "        print(\"score second model(val): %.2f\" %  (score_second))\n",
    "        elapsed_time = time.time() - start\n",
    "        print (\"elapsed_time:%.2f\" % elapsed_time + \"[sec]\")\n",
    "    print('total score:', np.array(scores).mean())\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "    \n",
    "    print('merge prediction')\n",
    "    start = time.time()\n",
    "    df_pred_train = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_b = pd.read_pickle(pred_train_temp.format(b))\n",
    "        df_pred_train = pd.concat([df_pred_train, df_b], axis=0, sort=False)\n",
    "\n",
    "    df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "    df_pred_train = df_pred_train.sort_values('id').reset_index(drop=True)\n",
    "    df_pred_train.to_pickle(pred_train.format(num_rep+1))\n",
    "    del df_pred_train, df_b\n",
    "    gc.collect()\n",
    "\n",
    "    # prepara test data\n",
    "    print('prepare test data')\n",
    "    start = time.time()\n",
    "    mols_test = df_test['molecule_name'].unique()\n",
    "    df_pred_test = pd.read_csv(pred_test.format(num_rep))\n",
    "    df_pred_test = df_pred_test.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_test_idx = pd.merge(df_test, df_pred_test, on=['id']).set_index('molecule_name')\n",
    "    df_map_test_idx = pd.read_pickle(map_test).set_index('molecule_name')\n",
    "    df_dist_test_idx = pd.read_pickle(dist_test).set_index('molecule_name')\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    # map test-data\n",
    "    print('map test-data')\n",
    "    \n",
    "    def map_test_data(temp_no):    \n",
    "        div = len(mols_test) // num_div\n",
    "        res = len(mols_test) % num_div\n",
    "        if temp_no == num_div - 1:\n",
    "            last_slice = div*(temp_no+1) + res\n",
    "        else:\n",
    "            last_slice = div*(temp_no+1)\n",
    "        df_map_pred_test = pd.DataFrame()\n",
    "        # for m in mols_test[:10]:\n",
    "        for m in mols_test[div*temp_no:last_slice]:\n",
    "            df_map_pred_test_temp = map_pred(df_pred_test_idx, df_map_test_idx, m)\n",
    "            df_map_pred_test = pd.concat([df_map_pred_test, df_map_pred_test_temp], axis=0, sort=False)\n",
    "        return pd.merge(df_map_pred_test, df_dist_test_idx, on=['id'])\n",
    "    \n",
    "    start = time.time()\n",
    "    with Pool(processes=num_div) as p:\n",
    "        df_pred_dist_test_list = p.map(map_test_data, [i for i in range(num_div)])\n",
    "#         p.join()\n",
    "    df_pred_dist_test = pd.concat(df_pred_dist_test_list, axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "    df_pred_dist_test.to_pickle(pred_dist_test)\n",
    "    del df_map_test_idx, df_dist_test_idx, df_pred_test_idx, df_pred_test\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    print('merge features_test')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        df_test_b = pd.read_pickle(first_test.format(b))\n",
    "        df_feature_test = pd.merge(df_test_b, df_pred_dist_test, on=['id'])\n",
    "        df_feature_test.to_pickle(features_test.format(b))\n",
    "        del df_feature_test, df_test_b\n",
    "        gc.collect()\n",
    "    del df_pred_dist_test\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    print('get test prediction')\n",
    "    start = time.time()\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "        df_bond = pd.read_pickle(features_test.format(b))\n",
    "        y_pred_b =[]\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'rb') as f:\n",
    "            gbm = pickle.load(f)\n",
    "\n",
    "        X_test = df_bond[df_bond.columns[5:]].values  \n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "        df_pred = pd.DataFrame([df_bond['id'], y_pred], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred['id'] = df_pred['id'].astype('int32')\n",
    "        df_pred.to_pickle(pred_test_temp.format(b))\n",
    "        del df_pred, gbm, df_bond\n",
    "        gc.collect()\n",
    "\n",
    "    df_submit = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_submit_b = pd.read_pickle(pred_test_temp.format(b))\n",
    "        df_submit = pd.concat([df_submit, df_submit_b], axis=0)\n",
    "\n",
    "    df_submit['id'] = df_submit['id'].astype('int32')\n",
    "    df_submit = df_submit.sort_values('id').reset_index(drop=True)\n",
    "    df_submit.to_csv(pred_test.format(num_rep+1), index=False)\n",
    "    del df_submit, df_submit_b\n",
    "    gc.collect()\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"total elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
