{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi gens! My idea is applying **Coulomb Interaction** which force is propotional to inversed squared distance (1/r^2). Inversed distance (1/r) can be applicable when focusing on potential. Anyway, i've considered inversed squared distance, here.\n",
    "\n",
    "1. get assigned atoms from train data which are included 'atom_index_0' or 'atom_index_1' of molecule\n",
    "2. get distances from each atom belonging to the molecule and pickup 'num = 5' nearest regarding to each atom [H, C, N, O, F]. Though in this competition we focus on bondings of H-H, H-C, H-N, properties of bondings are strongly affected O, F. That's why I'd like to consider interaction as I mentioned.\n",
    "3. mearge distance array according to atom_index_0 and atom_index_1 then dimension of feature of bonding is 50 = num x atoms x 2.\n",
    "4. feed the feature into model. model can be built for each bonding type, 1JHH, 1JHC, 2JHC etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mulliken_charges.csv',\n",
       " 'sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'potential_energy.csv',\n",
       " 'structures.csv',\n",
       " 'out',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dsgdb9nsd_000001.xyz',\n",
       " 'structures.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = '../../data_kaggle/champs/'\n",
    "OUTPUT = FOLDER + 'out/'\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mulliken_charges = pd.read_csv(FOLDER + 'mulliken_charges.csv')\n",
    "# df_sample =  pd.read_csv(FOLDER + 'sample_submission.csv')\n",
    "# df_magnetic_shielding_tensors = pd.read_csv(FOLDER + 'magnetic_shielding_tensors.csv')\n",
    "df_train = pd.read_csv(FOLDER + 'train.csv')\n",
    "df_test = pd.read_csv(FOLDER + 'test.csv')\n",
    "# df_dipole_moments = pd.read_csv(FOLDER + 'dipole_moments.csv')\n",
    "# df_potential_energy = pd.read_csv(FOLDER + 'potential_energy.csv')\n",
    "df_structures = pd.read_csv(FOLDER + 'structures.csv')\n",
    "# df_scalar_coupling_contributions = pd.read_csv(FOLDER + 'scalar_coupling_contributions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to find target bonding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pairs_list(df, df_structures, molecule_name):\n",
    "    pairs_list = []\n",
    "    df_tr = df.query('molecule_name == \"{}\"'.format(molecule_name))\n",
    "    df_st = df_structures.query('molecule_name == \"{}\"'.format(molecule_name))\n",
    "    \n",
    "    pairs_3JHH = df_tr.query('type == \"3JHH\"')[['atom_index_0','atom_index_1']].values\n",
    "    dist_matrix = get_dist_matrix(df_structures, molecule_name)\n",
    "\n",
    "    for p3 in pairs_3JHH:\n",
    "        atom_idx_0 = p3[0]\n",
    "\n",
    "        dist_arr = dist_matrix[atom_idx_0]\n",
    "        mask = dist_arr != 0\n",
    "        dist_arr_excl_0 = dist_arr[mask]\n",
    "        masked_idx = df_st['atom_index'].values[mask]\n",
    "        atom_idx_1 = masked_idx[np.argsort(dist_arr_excl_0)[0]]\n",
    "\n",
    "        atom_idx_3 = p3[1]\n",
    "        dist_arr = dist_matrix[atom_idx_3]\n",
    "        mask = dist_arr != 0\n",
    "        dist_arr_excl_0 = dist_arr[mask]\n",
    "        masked_idx = df_st['atom_index'].values[mask]\n",
    "        atom_idx_2 = masked_idx[np.argsort(dist_arr_excl_0)[0]]        \n",
    "        \n",
    "        pair = [atom_idx_0, atom_idx_1, atom_idx_2, atom_idx_3]\n",
    "        pairs_list.append(pair)\n",
    "        \n",
    "    return pairs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_3J(df_structures, molecule_name, atom_idx_list):\n",
    "    pos_list = []\n",
    "    df_st = df_structures.query('molecule_name == \"{}\"'.format(molecule_name))\n",
    "\n",
    "    for idx in atom_idx_list:\n",
    "        pos = df_st.query('atom_index == {}'.format(idx))[['x', 'y', 'z']].values\n",
    "        pos_list.append(pos)\n",
    "\n",
    "    v01 = pos_list[1] - pos_list[0]\n",
    "    v12 = pos_list[2] - pos_list[1]\n",
    "    v23 = pos_list[3] - pos_list[2]\n",
    "\n",
    "    v01_12 = v01 - ((np.dot(v01, v12.T) / np.linalg.norm(v12) **2 ) * v12)[0]\n",
    "    v23_12 = v23 - ((np.dot(v23, v12.T) / np.linalg.norm(v12) **2 ) * v12)[0]\n",
    "    \n",
    "    return np.dot(v01_12, v23_12.T) / np.linalg.norm(v01_12) / np.linalg.norm(v23_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:2082.4981682300568[sec]\n"
     ]
    }
   ],
   "source": [
    "mols = df_train_dist['molecule_name'].unique()\n",
    "col_cos = np.zeros(0)\n",
    "start = time.time()\n",
    "for m in mols:\n",
    "    df_tr = df_train.query('molecule_name == \"{}\"'.format(m))\n",
    "    pairs_list = gen_pairs_list(df_train, df_structures, m)\n",
    "    \n",
    "    cos_arr = np.zeros([df_tr.shape[0]])\n",
    "    cos = np.zeros(0)\n",
    "\n",
    "    for pair in pairs_list:\n",
    "        cos = np.hstack([cos, get_cos_3J(df_structures, m, pair)[0,0]])\n",
    "\n",
    "    mask = df_tr['type'].values == '3JHH'\n",
    "    cos_arr[mask] = cos\n",
    "    col_cos = np.hstack([col_cos, cos_arr])\n",
    "    \n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist['cos'] = col_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist.to_csv(OUTPUT + 'train_dist_3JHHcos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217045, 56)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_atoms_index(df, molecule):\n",
    "    se_0 = df.query('molecule_name == \"{}\"'.format(molecule))['atom_index_0']\n",
    "    se_1 = df.query('molecule_name == \"{}\"'.format(molecule))['atom_index_1']\n",
    "    assign_idx = pd.concat([se_0, se_1]).unique()\n",
    "    assign_idx.sort()\n",
    "    return assign_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_matrix(df_structures, molecule):\n",
    "    df_temp = df_structures.query('molecule_name == \"{}\"'.format(molecule))\n",
    "    locs = df_temp[['x','y','z']].values\n",
    "    num_atoms = len(locs)\n",
    "    loc_tile = np.tile(locs.T, (num_atoms,1,1))\n",
    "    dist_mat = ((loc_tile - loc_tile.T)**2).sum(axis=1)\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickup_dist_matrix(df, df_structures, molecule, num_pickup=5, atoms=['H', 'C', 'N', 'O', 'F']):\n",
    "    pickup_dist_matrix = np.zeros([0, len(atoms)*num_pickup])\n",
    "    assigned_idxs = assign_atoms_index(df, molecule) # [0, 1, 2, 3, 4, 5, 6] -> [1, 2, 3, 4, 5, 6]\n",
    "    dist_mat = get_dist_matrix(df_structures, molecule)\n",
    "    for idx in assigned_idxs: # [1, 2, 3, 4, 5, 6] -> [2]\n",
    "\n",
    "        \n",
    "        dist_arr = dist_mat[idx] # (7, 7) -> (7, )\n",
    "\n",
    "        atoms_mole = df_structures.query('molecule_name == \"{}\"'.format(mol))['atom'].values # ['O', 'C', 'C', 'N', 'H', 'H', 'H']\n",
    "        atoms_mole_idx = df_structures.query('molecule_name == \"{}\"'.format(mol))['atom_index'].values # [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "        mask_atoms_mole_idx = atoms_mole_idx != idx # [ True,  True, False,  True,  True,  True,  True]\n",
    "        masked_atoms = atoms_mole[mask_atoms_mole_idx] # ['O', 'C', 'N', 'H', 'H', 'H']\n",
    "        masked_atoms_idx = atoms_mole_idx[mask_atoms_mole_idx]  # [0, 1, 3, 4, 5, 6]\n",
    "        masked_dist_arr = dist_arr[mask_atoms_mole_idx]  # [ 5.48387003, 2.15181049, 1.33269675, 10.0578779, 4.34733927, 4.34727838]\n",
    "\n",
    "        sorting_idx = np.argsort(masked_dist_arr) # [2, 1, 5, 4, 0, 3]\n",
    "        sorted_atoms_idx = masked_atoms_idx[sorting_idx] # [3, 1, 6, 5, 0, 4]\n",
    "        sorted_atoms = masked_atoms[sorting_idx] # ['N', 'C', 'H', 'H', 'O', 'H']\n",
    "        sorted_dist_arr = 1/masked_dist_arr[sorting_idx] #[0.75035825,0.46472494,0.23002898,0.23002576,0.18235297,0.09942455]\n",
    "\n",
    "        target_matrix = np.zeros([len(atoms), num_pickup])\n",
    "        for a, atom in enumerate(atoms):\n",
    "            pickup_atom = sorted_atoms == atom # [False, False,  True,  True, False,  True]\n",
    "            pickup_dist = sorted_dist_arr[pickup_atom] # [0.23002898, 0.23002576, 0.09942455]\n",
    "            num_atom = len(pickup_dist)\n",
    "            if num_atom > num_pickup:\n",
    "                target_matrix[a, :] = pickup_dist[:num_pickup]\n",
    "            else:\n",
    "                target_matrix[a, :num_atom] = pickup_dist\n",
    "        pickup_dist_matrix = np.vstack([pickup_dist_matrix, target_matrix.reshape(-1)])\n",
    "    return pickup_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_atom(df, df_distance):\n",
    "    df_merge_0 = pd.merge(df, df_distance, left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'])\n",
    "    df_merge_0_1 = pd.merge(df_merge_0, df_distance, left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\n",
    "    del df_merge_0_1['atom_index_x'], df_merge_0_1['atom_index_y']\n",
    "    return df_merge_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 5\n",
    "# mols = df_train['molecule_name'].unique()\n",
    "# dist_mat = np.zeros([0, num*5])\n",
    "# atoms_idx = np.zeros([0], dtype=np.int32)\n",
    "# molecule_names = np.empty([0])\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# for mol in mols:\n",
    "    \n",
    "#     assigned_idxs = assign_atoms_index(df_train, mol)\n",
    "#     dist_mat_mole = get_pickup_dist_matrix(df_train, df_structures, mol, num_pickup=num)\n",
    "#     mol_name_arr = [mol] * len(assigned_idxs) \n",
    "    \n",
    "#     molecule_names = np.hstack([molecule_names, mol_name_arr])\n",
    "#     atoms_idx = np.hstack([atoms_idx, assigned_idxs])\n",
    "#     dist_mat = np.vstack([dist_mat, dist_mat_mole])\n",
    "    \n",
    "# col_name_list = []\n",
    "# atoms = ['H', 'C', 'N', 'O', 'F']\n",
    "# for a in atoms:\n",
    "#     for n in range(num):\n",
    "#         col_name_list.append('dist_{}_{}'.format(a, n))\n",
    "        \n",
    "# se_mole = pd.Series(molecule_names, name='molecule_name')\n",
    "# se_atom_idx = pd.Series(atoms_idx, name='atom_index')\n",
    "# df_dist = pd.DataFrame(dist_mat, columns=col_name_list)\n",
    "# df_distance = pd.concat([se_mole, se_atom_idx,df_dist], axis=1)\n",
    "\n",
    "# elapsed_time = time.time() - start\n",
    "# print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_distance.to_csv(OUTPUT + 'distance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = pd.read_csv(OUTPUT + 'distance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df_train_dist = merge_atom(df_train, df_dist)\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_dist.to_csv(OUTPUT + 'train_dist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dist = pd.read_csv(OUTPUT + 'train_dist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217045, 55)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_types = df_train_dist['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_score(y_val, y_pred):\n",
    "    return np.log(sum(np.linalg.norm(y_val- y_pred, axis=1)) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-dee391413209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-7cfeda9865ac>\u001b[0m in \u001b[0;36mtype_score\u001b[0;34m(y_val, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtype_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2479\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2482\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "scores = np.zeros([0])\n",
    "for i, b in enumerate(bond_types):\n",
    "    df = df_train_dist.query('type == \"{}\"'.format(b))\n",
    "    y = df['scalar_coupling_constant'].values\n",
    "    X = df[df.columns[5:]].values\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    model = lgb.LGBMRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_val).reshape(-1)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train).reshape(-1)\n",
    "    score = type_score(y_val, y_pred)\n",
    "    scores = np.hstack([scores, score])\n",
    "    print('type score:', score)\n",
    "    models.append(model)\n",
    "print('total score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, b in enumerate(bond_types):\n",
    "    df = df_train_dist.query('type == \"{}\"'.format(b))\n",
    "    y = df['scalar_coupling_constant'].values\n",
    "    X = df[df.columns[5:]].values\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = models[i]\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    plt.scatter(y_train, y_pred_train)\n",
    "    plt.scatter(y_val, y_pred)\n",
    "    plt.title('{}'.format(b))\n",
    "    plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
