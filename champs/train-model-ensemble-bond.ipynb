{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../../data_kaggle/champs/'\n",
    "OUTPUT = FOLDER + 'out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_score(y_val, y_pred):\n",
    "    return np.log(sum(np.abs(y_val- y_pred)) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 100000\n",
    "num_seed = 5\n",
    "bond_types = ['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 1JHC ----------\n",
      "seed No.0, bond type 1JHC\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-446f93f53b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgb_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             early_stopping_rounds=100)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodels_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "scores = []\n",
    "start0 = time.time()\n",
    "for i, b in enumerate(bond_types):\n",
    "    print('-'*10, b, '-'*10)\n",
    "    \n",
    "    df_bond = pd.read_pickle(OUTPUT + '20190701_dist_bond_dir_cos_train_{}.pickle'.format(b))\n",
    "    mols = df_bond['molecule_name'].unique()\n",
    "    num = len(mols)\n",
    "    num_train = int(num * 0.8)\n",
    "    pickup = random.sample(range(num), num)\n",
    "    pick_train = pickup[:num_train]\n",
    "    pick_val = pickup[num_train:]\n",
    "    \n",
    "    models_b = []\n",
    "    y_pred_b =[]\n",
    "    \n",
    "    df_train = df_bond[df_bond['molecule_name'].isin(mols[pick_train])]\n",
    "    y_train = df_train['scalar_coupling_constant'].values\n",
    "    X_train = df_train[df_train.columns[6:]].values\n",
    "\n",
    "    df_val = df_bond[df_bond['molecule_name'].isin(mols[pick_val])]\n",
    "    y_val = df_val['scalar_coupling_constant'].values\n",
    "    X_val = df_val[df_val.columns[6:]].values\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "        \n",
    "#     for s in range(num_seed):\n",
    "    s = 0\n",
    "    print('seed No.{}, bond type {}'.format(s, b))\n",
    "    start = time.time()\n",
    "\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : {'l2'},\n",
    "            'num_leaves' : 31,\n",
    "            'learning_rate' : 0.1,\n",
    "            'feature_fraction' : 0.9,\n",
    "            'bagging_fraction' : 0.8,\n",
    "            'bagging_freq': 5,\n",
    "        'seed':s\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=rounds,\n",
    "            verbose_eval=0,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=100)\n",
    "\n",
    "    models_b.append(gbm)\n",
    "    y_pred_single = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "    print(gbm.best_iteration)\n",
    "    print('single model score:',type_score(y_val, y_pred_single))\n",
    "\n",
    "    y_pred_b.append(y_pred_single)\n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "        \n",
    "    y_pred = np.array(y_pred_b).mean(axis=0)\n",
    "    score = type_score(y_val, y_pred)\n",
    "    print('mean-ensemble score:', score)\n",
    "    \n",
    "    with open(OUTPUT + '20190701_champs_models_lgb_{}.pickle'.format(b), 'wb') as f:\n",
    "        pickle.dump(models_b, f)\n",
    "\n",
    "    scores.append(score)\n",
    "elapsed_time = time.time() - start0\n",
    "print (\"total elapsed_time:{0}\".format(elapsed_time/3600) + \"[hours]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('type score:', scores)\n",
    "print('total score:', np.array(scores).mean())\n",
    "\n",
    "# type score: [-0.7107571299257489, -2.0767665113807867, -1.2548499603026722, -1.854568916875408, -1.4865422286105732, -2.074127209929504, -0.9917317367984064, -2.101555204837629]\n",
    "# total score: -1.568862362332591\n",
    "\n",
    "# type score: [-0.7395686378862215, -2.0418889965244227, -1.2178209199205257, -1.815672423977162, -1.4683662039626242, -0.705921299898279, -0.6104222463407887, -1.9517610071479379]\n",
    "# total score: -1.318927716957245\n",
    "\n",
    "# type score: [-0.7409293009193924, -2.0450323117743623, -1.1957051499369713, -1.8161131092290368, -1.4586015023036714, -1.9913312114848338, -0.9705676811755464, -2.0783924879920876]\n",
    "# total score: -1.5370840943519877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
