{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pred(df_pred_idx, df_map_idx, m, target_cols='predict'):\n",
    "    ids = df_pred_idx.loc[m]['id'].values\n",
    "    preds = df_pred_idx.loc[m]['predict'].values\n",
    "    pred_dict = {ids[i]:preds[i] for i in range(ids.shape[0])}\n",
    "    pred_dict[-1] = 0\n",
    "    df_sc_train = df_map_idx.loc[m][df_map_idx.columns[:-1]].replace(pred_dict)\n",
    "    df_sc_train['id'] = df_map_idx.loc[m]['id']\n",
    "    return df_sc_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '../../data_kaggle/champs/'\n",
    "OUTPUT = FOLDER + 'out/'\n",
    "TEMP = OUTPUT + 'temp/'\n",
    "MAP  = OUTPUT + 'map/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input\n",
    "df_train = pd.read_csv(FOLDER+'train.csv')\n",
    "df_test = pd.read_csv(FOLDER+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DATE = '20190721'\n",
    "VER = '02'\n",
    "MAP_DATE = '20190728'\n",
    "MODEL_DATE = '20190804'\n",
    "num_rep = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed input\n",
    "map_train = MAP + MAP_DATE + '_' + 'map_train.pickle'\n",
    "map_test = MAP + MAP_DATE + '_' + 'map_test.pickle'\n",
    "dist_train = MAP + MAP_DATE + '_' + 'dist_train.pickle'\n",
    "dist_test = MAP + MAP_DATE + '_' + 'dist_test.pickle'\n",
    "\n",
    "first_train = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_train_{}.pickle'#.format(b)\n",
    "first_test = OUTPUT + DATA_DATE + '_' + 'dist_ang_ori_bond_cos_test_{}.pickle'#.format(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "pred_train = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'pred_train_{}.pickle'#.format(num_rep)\n",
    "pred_test = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'submission_{}.csv'#.format(num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output files\n",
    "pred_dist_train = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'pred_dist_train.pickle'\n",
    "pred_dist_test = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'pred_dist_test.pickle'\n",
    "\n",
    "features_train = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'features_train_{}.pickle'#.format(b)\n",
    "features_test = OUTPUT + MODEL_DATE + '_' + VER + '_' + 'features_test_{}.pickle'#.format(b)\n",
    "\n",
    "trained_models = OUTPUT + MAP_DATE + '_' + VER + '_' + 'champs_models_lgb_{}_{}.pickle'#.format(b, num_rep)\n",
    "\n",
    "pred_train_temp = TEMP + 'pred_train_{}.pickle'\n",
    "pred_test_temp = TEMP + 'submission_{}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 20000\n",
    "params = {\n",
    "        'task' : 'train',\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'objective' : 'regression',\n",
    "        'metric' : {'l1'},\n",
    "        'num_leaves' : 15,\n",
    "        'learning_rate' : 0.1,\n",
    "        'feature_fraction' : 0.7,\n",
    "    'seed':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_types = ['3JHN', '3JHC','1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_div = 4\n",
    "temp_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map train-data\n",
    "def map_train_data(temp_no):\n",
    "    print('map train-data')\n",
    "    df_map_pred_train = pd.DataFrame()\n",
    "    # for m in mols_train[:10]:\n",
    "    div = len(mols_train) // num_div\n",
    "\n",
    "    # for m in mols_train[:10]:\n",
    "    if temp_no == num_div - 1:\n",
    "        last_slice = -1\n",
    "    else:\n",
    "        last_slice = div*(temp_no+1)\n",
    "\n",
    "    for m in mols_train[div*temp_no:last_slice]:\n",
    "        if m == mols_train[2]:\n",
    "            continue\n",
    "        df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0)\n",
    "\n",
    "        m = mols_train[2]\n",
    "        se_temp = pd.Series()\n",
    "    #     se_temp['molecule_name']  = m\n",
    "        se_temp['0'] = df_pred_train_idx.loc[m]['predict']\n",
    "        for i in range(48):\n",
    "            se_temp['{}'.format(i+1)] = 0.0\n",
    "        cols = df_map_pred_train_temp.columns[:-1]\n",
    "        df_map_pred_train_temp = pd.DataFrame(se_temp).T\n",
    "        df_map_pred_train_temp.columns = cols\n",
    "        df_map_pred_train_temp['id'] = df_pred_train_idx.loc[m]['id']\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "\n",
    "    return pd.merge(df_map_pred_train, df_dist_train_idx, on=['id'])\n",
    "#     df_pred_dist_train.to_pickle(pred_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseProcess.start of <Process(Process-2, initial)>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Process(target=map_train_data, args=(0,))\n",
    "p.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_rep in range(10):\n",
    "    print('repeat number:', num_rep)\n",
    "# prepare data\n",
    "    mols_train = df_train['molecule_name'].unique()\n",
    "    df_pred_train = pd.read_pickle(pred_train.format(num_rep))\n",
    "    df_pred_train = df_pred_train.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_train_idx = pd.merge(df_train, df_pred_train, on=['id']).set_index('molecule_name')\n",
    "    df_map_train_idx = pd.read_pickle(map_train).set_index('molecule_name')\n",
    "    df_dist_train_idx = pd.read_pickle(dist_train).set_index('molecule_name')\n",
    "\n",
    "    # map train-data\n",
    "    print('map train-data')\n",
    "    df_map_pred_train = pd.DataFrame()\n",
    "    # for m in mols_train[:10]:\n",
    "    for m in mols_train:\n",
    "        if m == mols_train[2]:\n",
    "            continue\n",
    "        df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0)\n",
    "\n",
    "        m = mols_train[2]\n",
    "        se_temp = pd.Series()\n",
    "    #     se_temp['molecule_name']  = m\n",
    "        se_temp['0'] = df_pred_train_idx.loc[m]['predict']\n",
    "        for i in range(48):\n",
    "            se_temp['{}'.format(i+1)] = 0.0\n",
    "        cols = df_map_pred_train_temp.columns[:-1]\n",
    "        df_map_pred_train_temp = pd.DataFrame(se_temp).T\n",
    "        df_map_pred_train_temp.columns = cols\n",
    "        df_map_pred_train_temp['id'] = df_pred_train_idx.loc[m]['id']\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "\n",
    "    df_pred_dist_train = pd.merge(df_map_pred_train, df_dist_train_idx, on=['id'])\n",
    "    df_pred_dist_train.to_pickle(pred_dist_train)\n",
    "    del df_map_pred_train, df_dist_train_idx, df_pred_train_idx, df_map_train_idx\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat number: 0\n",
      "map train-data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-53991e00dbcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdf_map_pred_train_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdf_map_pred_train_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_pred_train_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdf_map_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_map_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_map_pred_train_temp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdf_pred_dist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_map_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dist_train_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                        copy=copy, sort=sort)\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m    425\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 copy=self.copy)\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_uniform_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m             b = join_units[0].block.concat_same_type(\n\u001b[0;32m-> 2058\u001b[0;31m                 [ju.block for ju in join_units], placement=placement)\n\u001b[0m\u001b[1;32m   2059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m             b = make_block(\n",
      "\u001b[0;32m~/Documents/git/kaggle/ml/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mconcat_same_type\u001b[0;34m(self, to_concat, placement)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[1;32m    327\u001b[0m         values = self._concatenator([blk.values for blk in to_concat],\n\u001b[0;32m--> 328\u001b[0;31m                                     axis=self.ndim - 1)\n\u001b[0m\u001b[1;32m    329\u001b[0m         return self.make_block_same_class(\n\u001b[1;32m    330\u001b[0m             values, placement=placement or slice(0, len(values), 1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num_rep in range(10):\n",
    "    print('repeat number:', num_rep)\n",
    "# prepare data\n",
    "    mols_train = df_train['molecule_name'].unique()\n",
    "    df_pred_train = pd.read_pickle(pred_train.format(num_rep))\n",
    "    df_pred_train = df_pred_train.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_train_idx = pd.merge(df_train, df_pred_train, on=['id']).set_index('molecule_name')\n",
    "    df_map_train_idx = pd.read_pickle(map_train).set_index('molecule_name')\n",
    "    df_dist_train_idx = pd.read_pickle(dist_train).set_index('molecule_name')\n",
    "\n",
    "    # map train-data\n",
    "    print('map train-data')\n",
    "    df_map_pred_train = pd.DataFrame()\n",
    "    # for m in mols_train[:10]:\n",
    "    for m in mols_train:\n",
    "        if m == mols_train[2]:\n",
    "            continue\n",
    "        df_map_pred_train_temp = map_pred(df_pred_train_idx, df_map_train_idx, m)\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0)\n",
    "\n",
    "        m = mols_train[2]\n",
    "        se_temp = pd.Series()\n",
    "    #     se_temp['molecule_name']  = m\n",
    "        se_temp['0'] = df_pred_train_idx.loc[m]['predict']\n",
    "        for i in range(48):\n",
    "            se_temp['{}'.format(i+1)] = 0.0\n",
    "        cols = df_map_pred_train_temp.columns[:-1]\n",
    "        df_map_pred_train_temp = pd.DataFrame(se_temp).T\n",
    "        df_map_pred_train_temp.columns = cols\n",
    "        df_map_pred_train_temp['id'] = df_pred_train_idx.loc[m]['id']\n",
    "        df_map_pred_train = pd.concat([df_map_pred_train, df_map_pred_train_temp], axis=0, sort=False)\n",
    "\n",
    "    df_pred_dist_train = pd.merge(df_map_pred_train, df_dist_train_idx, on=['id'])\n",
    "    df_pred_dist_train.to_pickle(pred_dist_train)\n",
    "    del df_map_pred_train, df_dist_train_idx, df_pred_train_idx, df_map_train_idx\n",
    "    gc.collect()\n",
    "\n",
    "    print('merge features_train')\n",
    "    for b in bond_types:\n",
    "        df_train_b = pd.read_pickle(first_train.format(b))\n",
    "        df_feature_train = pd.merge(df_train_b, df_pred_dist_train, on=['id'])\n",
    "        df_feature_train.to_pickle(features_train.format(b))\n",
    "        del df_feature_train, df_train_b\n",
    "        gc.collect()\n",
    "\n",
    "    print('train models')\n",
    "    scores = []\n",
    "    with open(mols_split, 'rb') as f:\n",
    "        mols_train = pickle.load(f)\n",
    "        mols_val =  pickle.load(f)\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "\n",
    "        df = pd.read_pickle(features_train.format(b)).fillna(0)\n",
    "\n",
    "        df_train = df[df['molecule_name'].isin(mols_train)]    \n",
    "        y_train = df_train['scalar_coupling_constant'].values\n",
    "        X_train = df_train[df_train.columns[6:]].values\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "        df_val = df[df['molecule_name'].isin(mols_val)]\n",
    "        y_val = df_val['scalar_coupling_constant'].values\n",
    "        X_val = df_val[df_val.columns[6:]].values\n",
    "        lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=rounds,\n",
    "                verbose_eval=0,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'wb') as f:\n",
    "            pickle.dump(gbm, f)\n",
    "\n",
    "        y_val_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        y_train_pred = gbm.predict(X_train, num_iteration=gbm.best_iteration)\n",
    "\n",
    "        df_pred_train = pd.DataFrame([df_train['id'], y_pred_train], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "        df_pred_test = pd.DataFrame([df_test['id'], df_pred_test], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred_test['id'] = df_pred_test['id'].astype('int32')    \n",
    "\n",
    "        df_pred = pd.concat([df_pred_train, df_pred_test], axis=0, sort=False).sort_values('id').reset_index(drop=True)\n",
    "        df_pred.to_pickle(pred_train_temp.format(b))\n",
    "\n",
    "        score_first_train = type_score(y_train, X_train[:, -98])\n",
    "        score_second_train = type_score(y_train, y_train_pred)\n",
    "\n",
    "        score_first = type_score(y_val, X_val[:, -98])\n",
    "        score_second = type_score(y_val, y_val_pred)\n",
    "        scores.append(score_second)\n",
    "        print(gbm.best_iteration)\n",
    "        print(\"score first model(train): %.2f\" %  (score_first_train))\n",
    "        print(\"score second model(train): %.2f\" %  (score_second_train))\n",
    "        print(\"score first model(val): %.2f\" %  (score_first))\n",
    "        print(\"score second model(val): %.2f\" %  (score_second))\n",
    "        elapsed_time = time.time() - start\n",
    "        print (\"elapsed_time:%.2f\" % elapsed_time + \"[sec]\")\n",
    "    print('total score:', np.array(scores).mean())\n",
    "\n",
    "    print('merge prediction')    \n",
    "    df_pred_train = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_b = pd.read_pickle(pred_train_temp.format(b))\n",
    "        df_pred_train = pd.concat([df_pred_train, df_b], axis=0, sort=False)\n",
    "\n",
    "    df_pred_train['id'] = df_pred_train['id'].astype('int32')\n",
    "    df_pred_train = df_pred_train.reset_index(drop=True)\n",
    "    df_pred_train.to_pickle(pred_train.format(num_rep+1))\n",
    "    del df_pred_train, df_b\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # prepara test data\n",
    "    mols_test = df_test['molecule_name'].unique()\n",
    "    df_pred_test = pd.read_csv(pred_test.format(num_rep))\n",
    "    df_pred_test = df_pred_test.rename(columns={'scalar_coupling_constant':'predict'})\n",
    "    df_pred_test_idx = pd.merge(df_test, df_pred_test, on=['id']).set_index('molecule_name')\n",
    "    df_map_test_idx = pd.read_pickle(map_test).set_index('molecule_name')\n",
    "    df_dist_test_idx = pd.read_pickle(dist_test).set_index('molecule_name')\n",
    "\n",
    "    # map test-data\n",
    "    print('map test-data')\n",
    "    df_map_pred_test = pd.DataFrame()\n",
    "    # for m in mols_test[:10]:\n",
    "    for m in mols_test:\n",
    "        df_map_pred_test_temp = map_pred(df_pred_test_idx, df_map_test_idx, m)\n",
    "        df_map_pred_test = pd.concat([df_map_pred_test, df_map_pred_test_temp], axis=0, sort=False)\n",
    "    df_pred_dist_test = pd.merge(df_map_pred_test, df_dist_test_idx, on=['id'])\n",
    "    df_pred_dist_test.to_pickle(pred_dist_test)\n",
    "    del df_map_pred_test, df_map_pred_test_temp\n",
    "    gc.collect()\n",
    "\n",
    "    print('merge features_test')\n",
    "    for b in bond_types:\n",
    "        df_test_b = pd.read_pickle(first_test.format(b))\n",
    "        df_feature_test = pd.merge(df_test_b, df_pred_dist_test, on=['id'])\n",
    "        df_feature_test.to_pickle(features_test.format(b))\n",
    "        del df_feature_test, df_test_b\n",
    "        gc.collect()\n",
    "    del df_pred_dist_test\n",
    "    gc.collect()\n",
    "\n",
    "    print('get test prediction')\n",
    "    for b in bond_types:\n",
    "        print('-'*10, b, '-'*10)\n",
    "        start = time.time()\n",
    "        df_bond = pd.read_pickle(features_test.format(b))\n",
    "        y_pred_b =[]\n",
    "\n",
    "        with open(trained_models.format(b, num_rep+1), 'rb') as f:\n",
    "            gbm = pickle.load(f)\n",
    "\n",
    "        X_test = df_bond[df_bond.columns[5:]].values  \n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "        df_pred = pd.DataFrame([df_bond['id'], y_pred], index=['id', 'scalar_coupling_constant']).T\n",
    "        df_pred['id'] = df_pred['id'].astype('int32')\n",
    "        df_pred.to_pickle(pred_test_temp.format(b))\n",
    "        del df_pred, gbm, df_bond\n",
    "        gc.collect()\n",
    "\n",
    "    df_submit = pd.DataFrame()\n",
    "    for b in bond_types:\n",
    "        df_submit_b = pd.read_pickle(pred_test_temp.format(b))\n",
    "        df_submit = pd.concat([df_submit, df_submit_b], axis=0)\n",
    "\n",
    "    df_submit['id'] = df_submit['id'].astype('int32')\n",
    "    df_submit = df_submit.sort_values('id').reset_index(drop=True)\n",
    "    df_submit.to_csv(pred_test.format(num_rep+1), index=False)\n",
    "    del df_submit, df_submit_b\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4658147, 100) (2505542, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
